{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# the following line is not required if Dataset is installed as a python package.\n",
    "sys.path.append(\"../..\")\n",
    "from dataset import Dataset, DatasetIndex, Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of items in the dataset\n",
    "NUM_ITEMS = 10\n",
    "# number of items in a batch when iterating\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is defined by an index (a sequence of item ids) and a batch class (see [the documentation for details](https://analysiscenter.github.io/dataset/intro/dataset.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simplest case an index is a natural sequence 0, 1, 2, 3, ...\n",
    "\n",
    "So all you need to define the index is just a number of items in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(index=NUM_ITEMS, batch_class=Batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [the documentation](https://analysiscenter.github.io/dataset/intro/index.html) for more info about how to create an index which fits your needs.\n",
    "\n",
    "Here are the most frequent use cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    client_index = DatasetIndex(my_client_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    images_index = FilesIndex(path=\"/path/to/images/*.jpg\", no_ext=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate with gen_batch(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0  contains items [0 1 2]\n",
      "batch 1  contains items [3 4 5]\n",
      "batch 2  contains items [6 7 8]\n",
      "batch 3  contains items [9]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset.gen_batch(BATCH_SIZE, n_epochs=1)):\n",
    "    print(\"batch\", i, \" contains items\", batch.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop_last=True skips the last batch if it contains fewer than BATCH_SIZE items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0  contains items [0 1 2]\n",
      "batch 1  contains items [3 4 5]\n",
      "batch 2  contains items [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset.gen_batch(BATCH_SIZE, n_epochs=1, drop_last=True)):\n",
    "    print(\"batch\", i, \" contains items\", batch.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle permutes items across batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0  contains items [8 0 1]\n",
      "batch 1  contains items [9 6 7]\n",
      "batch 2  contains items [5 3 4]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset.gen_batch(BATCH_SIZE, n_epochs=1, drop_last=True, shuffle=True)):\n",
    "    print(\"batch\", i, \" contains items\", batch.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above multiple times to see how batches change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle can be bool, int (seed number) or a RandomState object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0  contains items [4 0 7]\n",
      "batch 1  contains items [5 8 3]\n",
      "batch 2  contains items [1 6 9]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset.gen_batch(BATCH_SIZE, n_epochs=1, drop_last=True, shuffle=123)):\n",
    "    print(\"batch\", i, \" contains items\", batch.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above multiple times to see that batches stay the same across runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate with next_batch(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `gen_batch` is a python generator, `next_batch` is an ordinary function.\n",
    "Most of the time you will use `gen_batch`, but for a deeper control over training and a more sophisticated finetuning `next_batch` might be more convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If too many iterations are made, `StopIteration` will be raised.\n",
    "\n",
    "Check that there are `NUM_ITEMS * 3` iterations (i.e. 3 epochs), but `n_epochs=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1 contains items [8 0 4]\n",
      "batch 2 contains items [9 6 1]\n",
      "batch 3 contains items [3 2 5]\n",
      "batch 4 contains items [7 8 0]\n",
      "batch 5 contains items [9 2 3]\n",
      "batch 6 contains items [5 6 4]\n",
      "got StopIteration\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_ITEMS * 3):\n",
    "    try:\n",
    "        batch = dataset.next_batch(BATCH_SIZE, shuffle=True, n_epochs=2, drop_last=True)\n",
    "        print(\"batch\", i + 1, \"contains items\", batch.indices)\n",
    "    except StopIteration:\n",
    "        print(\"got StopIteration\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally with shuffle=True, n_epochs=None and a variable batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not forget to reset iterator to start `next_batch`'ing from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_iter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_epochs=None` allows for infinite iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1 contains items [0 3 4]\n",
      "batch 2 contains items [2 6 1 8 9]\n",
      "batch 3 contains items [2 1 0 4 6]\n",
      "batch 4 contains items [5 7 9]\n",
      "batch 5 contains items [6 3 7 0]\n",
      "batch 6 contains items [8 5 2 4]\n",
      "batch 7 contains items [0 7 1]\n",
      "batch 8 contains items [4 2 8 5 6]\n",
      "batch 9 contains items [5 6 0 9 7]\n",
      "batch 10 contains items [4 1 8]\n",
      "batch 11 contains items [6 3 2 8]\n",
      "batch 12 contains items [0 5 9 1]\n",
      "batch 13 contains items [9 5 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(NUM_ITEMS * 1.3)):\n",
    "    batch = dataset.next_batch(BATCH_SIZE + (-1)**i * i % 3, shuffle=True, n_epochs=None, drop_last=True)\n",
    "    print(\"batch\", i + 1, \"contains items\", batch.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a deeper understanding of `drop_last` read [very important notes in the API](https://analysiscenter.github.io/dataset/api/dataset.index.html#dataset.DatasetIndex.next_batch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrative purposes let's create a small array which will serve as a raw data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 101, 102],\n",
       "       [103, 104, 105],\n",
       "       [106, 107, 108],\n",
       "       [109, 110, 111],\n",
       "       [112, 113, 114],\n",
       "       [115, 116, 117],\n",
       "       [118, 119, 120],\n",
       "       [121, 122, 123],\n",
       "       [124, 125, 126],\n",
       "       [127, 128, 129]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (100 + np.arange(NUM_ITEMS * 3)).reshape(NUM_ITEMS, -1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading data is available as `batch.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch contains items with indices [0 1 2]\n",
      "and batch data is\n",
      "[[100 101 102]\n",
      " [103 104 105]\n",
      " [106 107 108]]\n",
      "\n",
      "batch contains items with indices [3 4 5]\n",
      "and batch data is\n",
      "[[109 110 111]\n",
      " [112 113 114]\n",
      " [115 116 117]]\n",
      "\n",
      "batch contains items with indices [6 7 8]\n",
      "and batch data is\n",
      "[[118 119 120]\n",
      " [121 122 123]\n",
      " [124 125 126]]\n",
      "\n",
      "batch contains items with indices [9]\n",
      "and batch data is\n",
      "[[127 128 129]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset.gen_batch(BATCH_SIZE, n_epochs=1):\n",
    "    batch = batch.load(src=data)\n",
    "    print(\"batch contains items with indices\", batch.indices)\n",
    "    print('and batch data is')\n",
    "    print(batch.data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can easily iterate over batch items too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch contains\n",
      "[100 101 102]\n",
      "[103 104 105]\n",
      "[106 107 108]\n",
      "\n",
      "batch contains\n",
      "[109 110 111]\n",
      "[112 113 114]\n",
      "[115 116 117]\n",
      "\n",
      "batch contains\n",
      "[118 119 120]\n",
      "[121 122 123]\n",
      "[124 125 126]\n",
      "\n",
      "batch contains\n",
      "[127 128 129]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset.gen_batch(BATCH_SIZE, n_epochs=1):\n",
    "    batch = batch.load(src=data)\n",
    "    print(\"batch contains\")\n",
    "    for item in batch:\n",
    "        print(item)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not infrequently, the batch stores a more complex data structures, e.g. features and labels or images, masks, bounding boxes and labels. To work with these you might employ data components. Just define a property as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBatch(Batch):\n",
    "    components = 'features', 'labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = (200 + np.arange(NUM_ITEMS * 3)).reshape(NUM_ITEMS, -1)\n",
    "labels_array = np.random.choice(10, size=NUM_ITEMS)\n",
    "data = features_array, labels_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a dataset (`preloaded` handles data loading from data stored in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(index=NUM_ITEMS, batch_class=MyBatch, preloaded=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since components are defined, you can address them as batch and even item attributes (they are created and loaded automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0  contains items [0 1 2]\n",
      "and batch data consists of features:\n",
      "[[200 201 202]\n",
      " [203 204 205]\n",
      " [206 207 208]]\n",
      "and labels: [6 4 5]\n",
      "\n",
      "batch 1  contains items [3 4 5]\n",
      "and batch data consists of features:\n",
      "[[209 210 211]\n",
      " [212 213 214]\n",
      " [215 216 217]]\n",
      "and labels: [2 5 1]\n",
      "\n",
      "batch 2  contains items [6 7 8]\n",
      "and batch data consists of features:\n",
      "[[218 219 220]\n",
      " [221 222 223]\n",
      " [224 225 226]]\n",
      "and labels: [6 3 8]\n",
      "\n",
      "batch 3  contains items [9]\n",
      "and batch data consists of features:\n",
      "[[227 228 229]]\n",
      "and labels: [1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset.gen_batch(BATCH_SIZE, n_epochs=1)):\n",
    "    print(\"batch\", i, \" contains items\", batch.indices)\n",
    "    print(\"and batch data consists of features:\")\n",
    "    print(batch.features)\n",
    "    print(\"and labels:\", batch.labels)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can iterate over batch items and change them on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "item features: [200 201 202]     item label: 6\n",
      "item features: [203 204 205]     item label: 4\n",
      "item features: [206 207 208]     item label: 5\n",
      "\n",
      "You can change batch data, even scalars.\n",
      "New batch features:\n",
      " [[1200 1201 1202]\n",
      " [1203 1204 1205]\n",
      " [1206 1207 1208]]\n",
      "and labels: [106 104 105]\n",
      "\n",
      "Batch 1\n",
      "item features: [209 210 211]     item label: 2\n",
      "item features: [212 213 214]     item label: 5\n",
      "item features: [215 216 217]     item label: 1\n",
      "\n",
      "You can change batch data, even scalars.\n",
      "New batch features:\n",
      " [[1209 1210 1211]\n",
      " [1212 1213 1214]\n",
      " [1215 1216 1217]]\n",
      "and labels: [102 105 101]\n",
      "\n",
      "Batch 2\n",
      "item features: [218 219 220]     item label: 6\n",
      "item features: [221 222 223]     item label: 3\n",
      "item features: [224 225 226]     item label: 8\n",
      "\n",
      "You can change batch data, even scalars.\n",
      "New batch features:\n",
      " [[1218 1219 1220]\n",
      " [1221 1222 1223]\n",
      " [1224 1225 1226]]\n",
      "and labels: [106 103 108]\n",
      "\n",
      "Batch 3\n",
      "item features: [227 228 229]     item label: 1\n",
      "\n",
      "You can change batch data, even scalars.\n",
      "New batch features:\n",
      " [[1227 1228 1229]]\n",
      "and labels: [101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset.gen_batch(BATCH_SIZE, n_epochs=1)):\n",
    "    print(\"Batch\", i)\n",
    "    for item in batch:\n",
    "        print(\"item features:\", item.features, \"    item label:\", item.labels)\n",
    "\n",
    "    print()\n",
    "    print(\"You can change batch data, even scalars.\")\n",
    "    for item in batch:\n",
    "        item.features = item.features + 1000\n",
    "        item.labels = item.labels + 100\n",
    "    print(\"New batch features:\\n\", batch.features)\n",
    "    print(\"and labels:\", batch.labels)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For machine learning tasks you might need to split a dataset into train, test and validation parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.cv_split(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is split into train / test in 80/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.train), len(dataset.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.cv_split([.6, .2, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.train), len(dataset.test), len(dataset.validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset may be shuffled before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.cv_split(0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 9, 2, 6, 5, 7, 8]), array([0, 3, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train.indices, dataset.test.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, shuffle can be bool, int (seed number) or a RandomState object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.train` and `dataset.test` are also datasets so you can do anything you want including splitting them further into `dataset.train.train`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, though, you will work with pipelines, not datasets.\n",
    "\n",
    "See [the next tutorial](./02_pipeline_basic_operations.ipynb) for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
