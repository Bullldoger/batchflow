{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research class is intended for multiple running of the same pipelines with different parameters in order to get some statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare `VGG7` and `VGG16` performance on `MNIST` dataset with different layouts of convolutional blocks. For each combination of layout and model class, we will train model for 500 iterations and repeat that process 2 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dill\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from dataset import Pipeline, B, C, V\n",
    "from dataset.opensets import MNIST\n",
    "from dataset.models.tf import VGG7, VGG16\n",
    "from dataset.research import Research, Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model config. All parameters that we want to vary we define as ``C('parameter_name')``. In our case it's a `'body/block/layout'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_config={\n",
    "    'session/config': tf.ConfigProto(allow_soft_placement=True),\n",
    "    'inputs': dict(images={'shape': (28, 28, 1)},\n",
    "                   labels={'classes': 10, 'transform': 'ohe', 'name': 'targets'}),\n",
    "    'input_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    'output/ops': 'accuracy',\n",
    "    'device': C('device') # it's technical parameter for TFModel\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loading as a separate pipeline with lazy run. This is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST()\n",
    "train_root = mnist.train.p.run(BATCH_SIZE, shuffle=True, n_epochs=None, lazy=True)\n",
    "test_root = mnist.test.p.run(BATCH_SIZE, shuffle=True, n_epochs=1, lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define main parts of pipelines where we want to vary model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_template = (Pipeline()\n",
    "            .init_variable('loss', init_on_each_run=list)\n",
    "            .init_variable('accuracy', init_on_each_run=list)\n",
    "            .init_model('dynamic', C('model'), 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         fetches=['loss', 'output_accuracy'], \n",
    "                         feed_dict={'images': B('images'), 'labels': B('labels')},\n",
    "                         save_to=[V('loss'), V('accuracy')], mode='w')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_template = (Pipeline()\n",
    "            .init_variable('accuracy', init_on_each_run=list)\n",
    "            .import_model('conv', C('import_from'))\n",
    "            .to_array()\n",
    "            .predict_model('conv', \n",
    "                         fetches=['output_accuracy'], \n",
    "                         feed_dict={'images': B('images'), 'labels': B('labels')},\n",
    "                         save_to=[V('accuracy')], mode='a')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ppl = train_root + train_template\n",
    "test_ppl = test_root + test_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All parameter combinations we define through the dict where a key is a parameter name and value is a list of possible parameter values. Create a grid of parameters in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = Option('layout', ['cna', 'can']) * Option('model', [VGG7, VGG16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get all variants of config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = list(grid.gen_configs())\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element is a ConfigAlias. It's a Config dict of parameter values and dict with aliases for parameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[0].config(), configs[0].alias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the first case `model` is a class but in the second `str`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Research object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of `Research` class and add train and test pipelines and grid of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "            .pipeline(train_ppl, variables='loss', name='train')\n",
    "            .grid(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter ``name`` defines pipeline name inside ``research``. At each iteration train pipeline will be executed with ``.next_batch()`` and all ``variables`` from the pipeline will be saved so that variables should be added with ``mode='w'``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pipeline will be executed with ``.run()`` at each 100 iterations because of parameters ``run=True``  and ``execute='%100'``. `execute` can be `int` (iteration), `str` (`%{step})`) or `list` of `int` and `str`. Pipeline variable ``accuracy`` will be saved after each execution. In order to add a mean value of accuracy on test dataset, you can define a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(iteration, experiment, pipeline):\n",
    "    import numpy as np\n",
    "    pipeline = experiment[pipeline].pipeline\n",
    "    acc = pipeline.get_variable('accuracy')\n",
    "    return np.mean(acc)\n",
    "\n",
    "research.function(get_accuracy, returns='accuracy', name='test_accuracy', execute='%100', pipeline='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That function will get iterartion, experiment and kwargs (in that case it's `pipeline='test'`\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment is an OrderedDict for all pipelines and functions that were added to Research\n",
    "and are running in current job. Key is a name of ExecutableUnit (class for function and pipeline), value is ExecutableUnit.\n",
    "Each pipeline and function added to Research is saved as an ExecutableUnit. Each ExecutableUnit\n",
    "has the following attributes:\n",
    "\n",
    "    function : callable\n",
    "        is None if ExecutableUnit is a pipeline\n",
    "    pipeline : Pipeline\n",
    "        is None if ExecutableUnit is a function\n",
    "    root_pipeline : Pipeline\n",
    "        is None if ExecutableUnit is a function or pipeline is not divided into root and branch\n",
    "    result : dict\n",
    "        current results of the ExecutableUnit. Keys are names of variables (for pipeline)\n",
    "        or returns (for function) values are lists of variable values\n",
    "    path : str\n",
    "        path to the folder where results will be dumped\n",
    "    exec_for : int, list of ints or None\n",
    "    dump_for : int, list of ints or None\n",
    "    to_run : bool\n",
    "    variables : list\n",
    "        variables (for pipeline) or returns (for function)\n",
    "    on_root : bool\n",
    "    args : list\n",
    "    kwargs : dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you can start research. At each iteration units will be exuted in the same order as they were added into Research (if unit must be executed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# research.run(n_reps=10, n_iters=1000, name='my_research', progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but don't hurry up if you have a lot of gpus because you can do research much more faster, just define `workers=4` and `gpu = [0, 1, 2, 3]` as a list of available devices. In that case you can run 4 jobs in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# research.run(n_reps=10, n_iters=1000, workers=4, gpu=[0,1,2,3], name='my_research', progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you have heavy loading you can do it just one time for few pipelines with models. In that case you can define research in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "    .pipeline(root_pipeline=train_root, branch_pipeline=train_template, variables='loss', name='train')\n",
    "    .pipeline(root_pipeline=test_root, branch_pipeline=test_template,\n",
    "              variables='accuracy', name='test', run=True, execute='%100', import_from='train')\n",
    "    .grid(grid)\n",
    "    .function(get_accuracy, returns='accuracy', name='test_accuracy', execute='%100', pipeline='test')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve parallelization in branches we added `device` into model_config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you can define the number of branches in each worker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research.run(n_reps=2, n_iters=1000, workers=2, branches=2, gpu=[0,1,2,3], name='my_research', progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last iteration all results will be saved into `{research_name}/results/{config_alias}/{repetition_index}/{unitname}_{iteration}` add a dict pickled by dill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open('my_research/results/layout_can-model_VGG16/0/train_1000', 'rb') as f:\n",
    "    result_train = dill.load(f)\n",
    "\n",
    "with open('my_research/results/layout_can-model_VGG16/0/test_accuracy_1000', 'rb') as f:\n",
    "    result_test = dill.load(f)\n",
    "\n",
    "print(result_train.keys()) \n",
    "print(result_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(result_train['iteration'], result_train['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result_test['iteration'], result_test['accuracy'])\n",
    "plt.ylim((0,1))\n",
    "plt.xlim((0,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping of results and logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default if unit has `varaibles` or `returns` then results will be dumped at last iteration. But there is unit parameter `dump` that allows to save result not only in the end. It defines as `execute` parameter. For example, dump train results each 200 iterations. Besides, each research has log file. In order to add information about unit execution and dumping into log, define `logging=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "    .pipeline(root_pipeline=train_root, branch_pipeline=train_template, variables='loss', name='train', dump='%200')\n",
    "    .pipeline(root_pipeline=test_root, branch_pipeline=test_template,\n",
    "              variables='accuracy', name='test', run=True, execute='%100', import_from='train', logging=True)\n",
    "    .grid(grid)\n",
    "    .function(get_accuracy, returns='accuracy', name='test_accuracy', execute='%100', pipeline='test')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research.run(n_reps=2, n_iters=1000, workers=2, branches=2, gpu=[0,1,2,3], name='my_research', progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions on root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All functions and pipelines if `branches > 0` executed in parallel threads so sometime it can be a problem. In order to allow run function in main thread there exists parameter `on_root`. Function that will be added with `on_root=True` will get `iteration`, `experiments` and `kwargs`. `experiments` is a list of experiments that was defined above (`OrderedDict` of ExecutableUnits). Simple example of usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_root(iteration, experiments):\n",
    "    print(\"On root\", iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "    .function(on_root, on_root=True, execute=10, logging=True)\n",
    "    .pipeline(root_pipeline=train_root, branch_pipeline=train_template, variables='loss', name='train')\n",
    "    .pipeline(root_pipeline=test_root, branch_pipeline=test_template,\n",
    "              variables='accuracy', name='test', run=True, execute='%100', import_from='train', logging=True)\n",
    "    .grid(grid)\n",
    "    .function(get_accuracy, returns='accuracy', name='test_accuracy', execute='%100', pipeline='test')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That function will be executed just one time on 10 iteration and will be executed one time for all branches in task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "research.run(n_reps=1, n_iters=100, workers=2, branches=2, gpu=[0,1,2,3], name='my_research', progress_bar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
