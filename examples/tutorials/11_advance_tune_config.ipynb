{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This jupyter notebook is devoted to microbatch and train_mode. Notebook also shown how to use multiple GPUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries.\n",
    "Specify which GPU(s) to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7' \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "sys.path.append('../..')\n",
    "from batchflow import Pipeline, B, C, V, D\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.tf import VGG7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MNIST](http://yann.lecun.com/exdb/mnist/) is a dataset of handwritten digits frequently used as a baseline for machine learning tasks.\n",
    "\n",
    "Downloading MNIST database might take a few minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is defined by an index (a sequence of item ids) and a batch class (see [the documentation for details](https://analysiscenter.github.io/batchflow/intro/dataset.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST(bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a pipeline config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config allows to create flexible pipelines which take parameters.\n",
    "\n",
    "For instance, if you put a model type into config, you can run a pipeline against different models.\n",
    "\n",
    "See [a list of available models](https://analysiscenter.github.io/batchflow/intro/tf_models.html#ready-to-use-models) to choose the one which fits you best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(model=VGG7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Microbatching** allows to process given data sequentially, accumulating gradients from microbatches and applying them once in the end. The size of the microbatch can be specified in two places; the value that was specified last will be used.\n",
    "<span style=\"color:red\">**Microbatch size must be a divisor of the batch size!**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MICROBATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*scope* – subset of variables to optimize during training. Can be either string or sequence of strings.\n",
    "Value ```''``` is reserved for optimizing all trainable variables. Putting ```-``` sign before name stands for complement: optimize everything but the passed scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train_steps* – configuration of different training procedures. It allows to optimize parametrs of selected scope using selected optimizer, loss, decay. Optimizer and decay may be reused by another *train_step*. Use **train_mode** to select *train_step* and fetch loss according to this *train_step*. Watch [FreezeOut](https://arxiv.org/abs/1706.04983) to find out what it is for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**device** – allow train model on multiple GPU (Сreates a copy of model on each selected GPU). Initialization of large model on a large number of GPU may take some time (minuts or tens of minutes)!\n",
    "\n",
    "Example:\n",
    "```python\n",
    "'device': 'GPU:*'            # Used all avalible GPU\n",
    "'device': ['GPU:0', 'GPU:1'] # Used GPU:0 and GPU:1\n",
    "```\n",
    "<span style=\"color:red\">**Number of devices must be a divisor of the batch size! (If microbathing ~~batch size~~ microbatch size)**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay_config = ('exp', {'learning_rate': 0.005,\n",
    "                           'decay_steps': 100,\n",
    "                           'decay_rate': 0.99})\n",
    "\n",
    "model_config = {'inputs': {'images/shape': (B('image_shape')),\n",
    "                           'labels': {'classes': D('num_classes'),\n",
    "                                      'transform': 'ohe'}},\n",
    "                'initial_block': {'inputs': 'images'},\n",
    "                'microbatch': MICROBATCH_SIZE,\n",
    "                'train_steps': {'all': {'optimizer': 'Adam'},\n",
    "                                'all_with_decay': {'optimizer': 'Adam', 'decay': lr_decay_config},\n",
    "                                'custom': {'optimizer': 'RMSProp', 'scope': '-body/group-0', 'decay': lr_decay_config},\n",
    "                                'part_head': {'use': 'all', 'scope': 'head/layer-2', 'loss': 'mse'}\n",
    "                               }\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a template pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_template = (Pipeline(config=config)\n",
    "                  .to_array()\n",
    "                  .train_model(name='conv_nn',\n",
    "                               use_lock=True,\n",
    "                               fetches='loss_all', \n",
    "                               images=B('images'), \n",
    "                               labels=B('labels'),\n",
    "                               save_to=V('current_loss'), \n",
    "                               train_mode='all')\n",
    "                  .update_variable('loss_history', V('current_loss'), mode='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<batchflow.once_pipeline.OncePipeline at 0x7f8d6d75f4e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_template.before\n",
    " .init_variable('loss_history', init_on_each_run=list)\n",
    " .init_variable('current_loss')\n",
    " .init_model(mode='dynamic',\n",
    "             model_class=C('model'),\n",
    "             name='conv_nn',\n",
    "             config=model_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a dataset to a template pipeline to create a runnable pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (train_template << dataset.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c5dd58ac0c471c8df1fb0f7f381d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=937), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f8d6da8de48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline.run(BATCH_SIZE, shuffle=True, n_epochs=1, bar='n', drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = (Pipeline()\n",
    "                 .import_model(model='conv_nn', \n",
    "                               pipeline=train_pipeline)\n",
    "                 .to_array()\n",
    "                 .predict_model(name='conv_nn',\n",
    "                                fetches='predictions', \n",
    "                                images=B('images'), \n",
    "                                save_to=V('predictions'))\n",
    "                 .gather_metrics('class', targets=B('labels'), predictions=V('predictions'),\n",
    "                                 fmt='logits', axis=-1, save_to=V('metrics', mode='a')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<batchflow.once_pipeline.OncePipeline at 0x7f8d4af115c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_pipeline.before\n",
    " .init_variable('predictions') \n",
    " .init_variable('metrics', init_on_each_run=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = (test_pipeline << dataset.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1591728d94149c1815ce4cd03fb5009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f8dd0c7ab38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipeline.run(BATCH_SIZE, shuffle=True, n_iters=3, bar='n', prefetch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the accumulated [metrics information](https://analysiscenter.github.io/batchflow/intro/models.html#model-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = test_pipeline.get_variable('metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9895833333333334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.evaluate('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
