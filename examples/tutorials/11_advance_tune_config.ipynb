{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This jupyter notebook focuses on advanced parametrs of model config:\n",
    "1. [microbatch](#microbatch)\n",
    "2. [device](#device)\n",
    "3. [train_steps](#train_steps)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries.\n",
    "Specify which GPU(s) to be used. More about it in [CUDA documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7' # specify which GPU(s) to be used\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "sys.path.append('../..')\n",
    "from batchflow import Pipeline, B, C, V, D\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.tf import VGG7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading MNIST. You now about MNIST from [here](./02_pipeline_operations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST(bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Define a pipeline config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default pipeline config. You now about it from [this notebook](./03_ready_to_use_model_tf.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(model=VGG7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Define a model config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default model config.\n",
    "\n",
    "Additional advanced options will be added to model_config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {'inputs': {'images/shape': (B('image_shape')),\n",
    "                           'labels': {'classes': D('num_classes'),\n",
    "                                      'transform': 'ohe'}},\n",
    "                'initial_block': {'inputs': 'images'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='microbatch'></a>\n",
    "### Microbatch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Microbatching** allows to process given data sequentially, accumulating gradients from microbatches and applying them once in the end. The size of the microbatch can be specified in two places; the value that was specified last will be used.\n",
    "\n",
    "<font color='red'>**Microbatch size must be a divisor of the batch size!**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set size of microbatch 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.update({'microbatch': 32})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we run the pipeline, the model will receive batches with size 32 not BATCH_SIZE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='device'></a>\n",
    "### device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need more than one GPU if model training time consumes a significant fraction of execution pipeline time.\n",
    "\n",
    "Parameter **device** allows train model on multiple GPU (Сreates a copy of model on each selected GPU).\n",
    "Initialization of large model on a large number of GPU may take some time (minuts or tens of minutes)! \n",
    "\n",
    "Parameter **device** can be either string or sequence of strings.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "'device': 'GPU:0'            # Used only GPU:0\n",
    "'device': ['GPU:0', 'GPU:1'] # Used GPU:0 and GPU:1\n",
    "'device': 'GPU:*'            # Used all avalible GPU\n",
    "```\n",
    "<font color='red'>**Number of devices must be a divisor of the batch size! (If microbathing ~~batch size~~ microbatch size)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='train_steps'></a>\n",
    "### train_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*scope* – subset of weights to optimize during training. Can be either string or sequence of strings.\n",
    "Value ```''``` is reserved for optimizing all trainable variables. Putting ```-``` sign before name stands for complement: optimize everything but the passed scope. Scope can be choosen from masks of the path to the model weights tensors.\n",
    "\n",
    "Also can be used list of scopes:\n",
    "```python\n",
    "'scope': ['block/group-0/some_layer', 'block/some_group']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_steps** – configuration of different training procedures. It allows to optimize parametrs of selected scope using selected optimizer, loss, decay.  Watch [FreezeOut](https://arxiv.org/abs/1706.04983) to find out what it is.\n",
    "\n",
    "Give name (key of dict) of train_step as you wish. Choose optimizer, scope of weights of your neural network,\n",
    "and learning rate decay config ([Avalible losses and decays](https://analysiscenter.github.io/batchflow/api/batchflow.models.tf.base.html)). For example:\n",
    "\n",
    "\n",
    "```python\n",
    "'train_steps': {'name_of_train_step': {'optimizer': 'Adam', \n",
    "                                       'scope': 'block/group/layer', \n",
    "                                       'decay': lr_decay_config, \n",
    "                                       'loss': 'mse'}}\n",
    "```\n",
    "\n",
    "Parameter **train_mode** used in train_model to select *train_step*. \n",
    "To fetch loss according to selected *train_step* use ```fetches='loss_name_of_train_step'```.\n",
    "\n",
    "\n",
    "When used:\n",
    "```python \n",
    "train_mode='name_of_train_step'\n",
    "```\n",
    "selected ```name_of_train_step``` train_step with selected config inside: optimizer - ```Adam```,\n",
    "learninig rate decay preset in ```lr_decay_config```, loss - ```mse```, and optimize only weights in ```block/group/layer```.  When the model is training loss according ```name_of_train_step``` *train_step* can be fetched as ```fetches='loss_name_of_train_step'```.\n",
    "\n",
    "#### train_steps works only on tensorflow models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add *train_steps* in model_config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay_config = ('exp', {'learning_rate': 0.005,\n",
    "                           'decay_steps': 100,\n",
    "                           'decay_rate': 0.96})\n",
    "\n",
    "model_config.update({'train_steps': \n",
    "                     {'all': {'optimizer': 'Adam'},\n",
    "                      'all_with_decay': {'optimizer': 'Adam', 'decay': lr_decay_config},\n",
    "                      'custom': {'optimizer': 'RMSProp', 'scope': '-body/block-0', 'decay': lr_decay_config},\n",
    "                      'part_head': {'use': 'all', 'scope': 'head/layer-2', 'loss': 'mse'}\n",
    "                      }})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also scope contain all trainable variables if it is not set (As in the case ```'all'``` or ```'all_with_decay'```).\n",
    "\n",
    "Optimizer and decay together may be reused by another *train_step*. Use key ```'use'``` and name of *train_step* to do that (As in the case ```'part_head'```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.update({'device': 'CPU:*'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train model used all avalible GPU(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Create a template pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use ```train_mode='all'``` to select train_step ```'all'```. You could see such pipeline and all that comes next in [3 tutorial](./03_ready_to_use_model_tf.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<batchflow.once_pipeline.OncePipeline at 0x7f15da1be2e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_template = (Pipeline(config=config)\n",
    "                  .to_array()\n",
    "                  .train_model(name='conv_nn',\n",
    "                               use_lock=True,\n",
    "                               fetches='loss_all', \n",
    "                               images=B('images'), \n",
    "                               labels=B('labels'),\n",
    "                               save_to=V('current_loss'), \n",
    "                               train_mode='all')\n",
    "                  .update_variable('loss_history', V('current_loss'), mode='a'))\n",
    "\n",
    "(train_template.before\n",
    " .init_variable('loss_history', init_on_each_run=list)\n",
    " .init_variable('current_loss')\n",
    " .init_model(mode='dynamic',\n",
    "             model_class=C('model'),\n",
    "             name='conv_nn',\n",
    "             config=model_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a dataset to a template pipeline to create a runnable pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 937/937 [15:39<00:00,  1.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f15da1b3cc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline = train_template << dataset.train\n",
    "train_pipeline.run(BATCH_SIZE, shuffle=True, n_epochs=1, bar=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<batchflow.once_pipeline.OncePipeline at 0x7f15b3ae93c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipeline = (Pipeline()\n",
    "                 .to_array()\n",
    "                 .predict_model(name='conv_nn',\n",
    "                                fetches='predictions', \n",
    "                                images=B('images'), \n",
    "                                save_to=V('predictions'))\n",
    "                 .gather_metrics('class', targets=B('labels'), predictions=V('predictions'),\n",
    "                                 fmt='logits', axis=-1, save_to=V('metrics', mode='a')))\n",
    "\n",
    "(test_pipeline.before\n",
    " .init_variable('predictions') \n",
    " .init_variable('metrics', init_on_each_run=None)\n",
    " .import_model(model='conv_nn',\n",
    "               pipeline=train_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 156/157 [00:40<00:00,  4.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f15da1b3c88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipeline = (test_pipeline << dataset.test)\n",
    "test_pipeline.run(BATCH_SIZE, shuffle=True, n_epochs=1, bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the accumulated [metrics information](https://analysiscenter.github.io/batchflow/intro/models.html#model-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912420382165605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = test_pipeline.get_variable('metrics')\n",
    "metrics.evaluate('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
