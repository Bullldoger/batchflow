{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the point of multi-GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need more than one GPU if model training time consumes a significant fraction of execution pipeline time.\n",
    "\n",
    "If you have several GPUs, you can use them to train model. This will speed up training process of the model. \n",
    "\n",
    "Parameter `device` allows train model on multiple GPU (Сreates a copy of model on each selected GPU).\n",
    "Initialization of large model on a large number of GPU may take some time (minuts or tens of minutes)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from batchflow import Pipeline, B, C, V, D\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.tf import VGG7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify which GPU(s) to be used. More about it in [CUDA documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=5,6\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=5,6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset, define a pipeline config, define a default model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST(bar=True)\n",
    "\n",
    "config = dict(model=VGG7)\n",
    "\n",
    "model_config = {'inputs': {'images/shape': B.image_shape,\n",
    "                           'labels': {'classes': D.num_classes,\n",
    "                                      'transform': 'ohe'}},\n",
    "                'initial_block': {'inputs': 'images'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on one GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<batchflow.once_pipeline.OncePipeline at 0x7f4fee13a278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_template = (Pipeline(config=config)\n",
    "                  .to_array()\n",
    "                  .train_model('conv_nn', fetches='loss', \n",
    "                               images=B.images, labels=B.labels,\n",
    "                               save_to=V('loss_history', mode='a'),\n",
    "                               use_lock=True))\n",
    "\n",
    "(train_template.before\n",
    " .init_variable('loss_history', default=[])\n",
    " .init_model('dynamic', C('model'),'conv_nn',\n",
    "             config=model_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:01<00:00,  4.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f4ffe14d2e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline = train_template << dataset.train\n",
    "train_pipeline.run(BATCH_SIZE, shuffle=True, n_iters=1000, bar=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training lasted 4 minutes on one GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use `device` and set up 2 GPUs to train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.update({'device': ['GPU:0', 'GPU:1']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter `device` can be either string or sequence of strings.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "'device': 'GPU:0'                     # Used only GPU:0\n",
    "'device': ['GPU:0', 'GPU:1', 'GPU:2'] # Used GPU:0, GPU:1 and GPU:2\n",
    "'device': 'GPU:*'                     # Used all avalible GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NUMBER OF DEVICES MUST BE A DEVISOR OF THE BATCH SIZE! (IF MICROBATHING ~~BATCH SIZE~~ MICROBATCH SIZE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on several GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<batchflow.once_pipeline.OncePipeline at 0x7f4f2c4bcef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_template_multi = (Pipeline(config=config)\n",
    "                        .to_array()\n",
    "                        .train_model('conv_nn', fetches='loss', \n",
    "                                     images=B.images, labels=B.labels,\n",
    "                                     save_to=V('loss_history', mode='a'), \n",
    "                                     use_lock=True))\n",
    "\n",
    "(train_template_multi.before\n",
    " .init_variable('loss_history', default=[])\n",
    " .init_model('dynamic', C('model'),'conv_nn',\n",
    "             config=model_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:44<00:00,  6.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f4f2c4bcfd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline_multi = train_template_multi << dataset.train\n",
    "train_pipeline_multi.run(BATCH_SIZE, shuffle=True, n_iters=1000, bar=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training lasted 2:44 on two GPUs it is significant increase of training speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `device` you can decrease training time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU and microbathing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Schematic illustration of the formation of batches to each GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Batch_microbatch_GPU.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `microbatch` and `device` at the same time. If we have huge batches it be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add microbathing and define new batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.update({'microbatch': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_2 = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with several GPUs and microbatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<batchflow.once_pipeline.OncePipeline at 0x7f4d7c692ba8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_multi_micro = (Pipeline(config=config)\n",
    "                        .to_array()\n",
    "                        .train_model('conv_nn', fetches='loss', \n",
    "                                     images=B.images, labels=B.labels,\n",
    "                                     save_to=V('loss_history', mode='a'), \n",
    "                                     use_lock=True))\n",
    "\n",
    "(template_multi_micro.before\n",
    " .init_variable('loss_history', default=[])\n",
    " .init_model('dynamic', C('model'),'conv_nn',\n",
    "             config=model_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:39<00:00,  1.53s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f4d7c68f358>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_multi_micro = template_multi_micro << dataset.train\n",
    "pipeline_multi_micro.run(BATCH_SIZE_2, shuffle=True, n_iters=100, bar=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training finish without error it means that we can use `device` and `microbatch` together. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
