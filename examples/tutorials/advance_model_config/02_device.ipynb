{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the point of multi-GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need more than one GPU if model training time consumes a significant fraction of execution pipeline time. \n",
    "Therefore, if you have several GPUs, you can use all of them to train model. This will speed up training process of the model. \n",
    "\n",
    "Parameter `device` allows train model on multiple GPU (Сreates a copy of model on each selected GPU).\n",
    "Next, batch data is split across available GPUs and gradients compute separately and averaged.\n",
    "\n",
    "Initialization of large model on a large number of GPU may take some time (minuts or tens of minutes)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from batchflow import Pipeline, B, C, V, D, C\n",
    "from batchflow.opensets import Imagenette320\n",
    "from batchflow.models.tf import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify which GPU(s) to be used. More about it in [CUDA documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3,4,5,6,7\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3,4,5,6,7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset, define a default model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:15<00:15, 15.82s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = Imagenette320(bar=True)\n",
    "\n",
    "model_config = {'inputs/images/shape': B.image_shape,\n",
    "                'inputs/labels/classes': D.num_classes,\n",
    "                'initial_block/inputs': 'images'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on single GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By default, if one or more GPUs are visible for the pipeline model, model uses only first GPU!** Now it's `'GPU:0'`. You can also configure it directly and we will talk about it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {'model_config': model_config}\n",
    "\n",
    "template = (Pipeline()\n",
    "            .init_variable('loss_history', [])\n",
    "            .init_model('dynamic', ResNet18,'conv_nn', config=C('model_config'))\n",
    "            .resize((320, 320))\n",
    "            .to_array()\n",
    "            .train_model('conv_nn', fetches='loss',\n",
    "                         images=B.images, labels=B.labels,\n",
    "                         save_to=V('loss_history', mode='a'), use_lock=True))\n",
    "\n",
    "pipeline_single = template << dataset.train << default_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the next cell execution time is spent on the initialization model. Further, we will compare initialization model on one GPU and multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 4.21 s, total: 16.4 s\n",
      "Wall time: 16.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.batch_image.ImagesBatch at 0x7f5b15dbf630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "template_single.next_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:29<00:00,  2.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f5b153dd0f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_single.run(BATCH_SIZE, shuffle=True, n_epochs=1, bar=True, drop_last=True, prefetch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use `device` and set up 2 GPUs to train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.update({'device': ['GPU:1', 'GPU:2']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter `device` can be string, list of strings or regular expression.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "'device': 'GPU:0'                     # Used only GPU:0\n",
    "'device': ['GPU:0', 'GPU:1', 'GPU:2'] # Used GPU:0, GPU:1 and GPU:2\n",
    "'device': 'GPU:*'                     # Used all avalible GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **BATCH SIZE MUST BE DIVISIBLE BY NUMBER OF DEVICES! (IF MICROBATHING ~~BATCH SIZE~~ MICROBATCH SIZE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on multiple GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_multiple_GPUs = {'model_config': model_config}\n",
    "\n",
    "pipeline_multi = template << dataset.train << config_multiple_GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.6 s, sys: 3.17 s, total: 31.7 s\n",
      "Wall time: 30.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.batch_image.ImagesBatch at 0x7f595050b6a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_multi.next_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:01<00:00,  3.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f5950496e80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_multi.run(BATCH_SIZE, shuffle=True, n_epochs=1, bar=True, drop_last=True, prefetch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model’s training time is about 1 minute on two GPUs. If we add more GPUs, we get even less training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU and microbathing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Schematic illustration of the formation of batches to each GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Batch_microbatch_GPU.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `microbatch` and `device` at the same time. If we have huge batches it will be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add microbathing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.update({'device': ['GPU:3', 'GPU:4']})\n",
    "model_config.update({'microbatch': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with multiple GPUs and microbatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_multiple_microbatch = {'model_config': model_config}\n",
    "\n",
    "pipeline_multi_micro = template_multi_micro << dataset.train << config_multiple_microbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.9 s, sys: 3.4 s, total: 35.3 s\n",
      "Wall time: 32.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.batch_image.ImagesBatch at 0x7f55507819b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_multi_micro.next_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [02:56<00:00,  1.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x7f5550781b00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_multi_micro.run(BATCH_SIZE, shuffle=True, n_epochs=1, bar=True, drop_last=True, prefetch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training finishes without error, it means that we can use the `device` and the `microbatch` together. Look at the training time of the model with one GPU, the model with two GPUs and the last model. When we add one more GPU to the first model (make the second model) we got speed up training time is reduced by 1.5 times! \n",
    "Training time does not decrease by 2 times because overheads appear during information exchange between multiple GPUs. \n",
    "When we add `microbatch` to the second model we increasing training time (More about that in [01_microbatch tutorial](./01_microbatch.ipynb)).\n",
    "\n",
    "As stated at the beginning initialization model on multiple GPUs spent more time than initialization on one GPU (See cells with magic command `%%time`).\n",
    "\n",
    "If you will use multiple GPUs, you can save tens of hours of training the model or even more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next tutorial is about [different training procedures](./03_train_steps.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
