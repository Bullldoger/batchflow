{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Ordinary Torch Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a torch model as an instance of `torch.nn.Module` it can be easily integrated into a training or inference pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from batchflow import Pipeline, B, C, D, V, W\n",
    "from batchflow.models.torch import TorchModel\n",
    "from batchflow.opensets import Imagenette160\n",
    "from batchflow.utils import plot_images\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [Imagenette](https://github.com/fastai/imagenette) dataset. It may take few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Imagenette160()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment with [MNIST](https://analysiscenter.github.io/batchflow/api/batchflow.opensets.html#mnist) and [CIFAR](https://analysiscenter.github.io/batchflow/api/batchflow.opensets.html#cifar100) datasets as well.   \n",
    "Download and use them in the same manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `resnet34` model from `torchvision.models` zoo.   \n",
    "In the config you must specify that the `body` of your model is `resnet34` module. Optionally you could add more laysers on top of the net by specifying `head`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate this with example. `resnet34` model, like all classification networks from `torchvision.models` zoo, is customized for `Imagenet` dataset, i.e. have dense layer on top of it with 1000 neurons.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the last 4 layers of `resnet34`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet34().modules())[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the `Imagenette` dataset is a subset of `Imagenet` and has only 10 classes.   \n",
    "To customize the network for our dataset, we could add the `Dense` layer with 10 neurons on top of the `resnet34` model.   \n",
    "However, that's not a very good model since it contains 2 extremely large dense layers.   \n",
    "Instead, we remove the last `Dense` and `Global pool` layers of `resnet34`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(resnet34().children())[:-2]\n",
    "model = torch.nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as an alternative let's  place `conv, kernel_size = 1 and out_filters=10` and `Global pool` layers on top of the network using batchflow [ConvBlock](https://analysiscenter.github.io/batchflow/api/batchflow.models.torch.layers.html#batchflow.models.torch.layers.ConvBlock)      \n",
    "This block is a convenient building block for concise, yet very expressive neural networks.   \n",
    "Note that in this case you need to specify the shape of the tensor passing from `body` to `head` via `head/inputs` key in the config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shape can be easile infered. Note that all the images are cropped with the crop shape `(160,160)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 160, 160)\n",
    "output = model(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'inputs/images/shape': (3, 160, 160),\n",
    "          'inputs/labels/classes': 10,\n",
    "          'initial_block/inputs': 'images',\n",
    "          'body': model,\n",
    "          'head': dict(layout='cV', filters=10, kernel_size=1),\n",
    "          'head/inputs': (None, 512, 5, 5),\n",
    "          'loss': 'ce',\n",
    "          'output/predicted': ['proba'],\n",
    "          'device': 'gpu:6'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pipeline we apply two preprocessing steps to the batch of images.   \n",
    "First, we crop the images so the whole batch consists of the crops with the same size.   \n",
    "Secondly, convert the batch of PIL images to the numpy array to make it compatible with torch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (dataset.train.p\n",
    "                    .init_variable('loss_history', default=[])\n",
    "                    .init_model('dynamic', TorchModel, 'my_model', config)\n",
    "                    .crop(shape=(160, 160), origin='center')\n",
    "                    .to_array(channels='first', dtype='float32') \n",
    "                    .train_model('my_model', B.images, B.labels, fetches='loss',\n",
    "                                 save_to=V('loss_history', mode='a'))\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training may take some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss is: 0.2118381:  96%|█████████▋| 2895/3000 [08:33<00:18,  5.77it/s] "
     ]
    }
   ],
   "source": [
    "train_pipeline.run(64, shuffle=True, n_iters=3000, drop_last=True, bar=True,\n",
    "                   bar_desc=W(V('loss_history')[-1].format('Loss is: {:7.7}')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the loss function plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(train_pipeline.v('loss_history'))\n",
    "plt.xlabel(\"Iterations\"), plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training might be continued as the loss is not on plateu yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = (dataset.test.p\n",
    "                    .init_variable('predictions')\n",
    "                    .init_variable('metrics', default=None)\n",
    "                    .import_model('my_model', train_pipeline)\n",
    "                    .crop(shape=(160,160), origin='center')\n",
    "                    .to_array(channels='first', dtype='float32') # make it compatible with torch models\n",
    "                    .predict_model('my_model', B.images,\n",
    "                                   fetches='predicted_proba', save_to=V('predictions'))\n",
    "                    .gather_metrics('class', targets=B.labels, predictions=V('predictions'),\n",
    "                                    fmt='proba', axis=-1, save_to=V('metrics', mode='a'))\n",
    "                    .apply_transform_all(src='images', dst='images', \n",
    "                                     func=lambda x: np.transpose(x, (0, 2, 3, 1)).astype(int)) # make it compatible with plt.imshow()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline.run(50, shuffle=True, n_epochs=1, drop_last=False, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = test_pipeline.get_variable('metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.evaluate('accuracy')\n",
    "print('Accuracy on the test set - {:.3}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and pass the batch of images through the trained network and look in more details at the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_pipeline.next_batch(10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(batch.images, batch.labels, batch.pipeline.v('predictions'),\n",
    "                        classes=dataset.name_classes, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial you have learnt how easily ordinary `pytorch` models can be customized and integrated into `batchflow` pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can go futher in your experiments and train the network with 2 `Dense` layers on top of it as was mentioned before to find out whether significant increase in the number of parameters will result in the increase of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
