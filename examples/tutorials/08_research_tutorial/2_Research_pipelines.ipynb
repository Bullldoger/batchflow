{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Execution Strategies with Research Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction to Research Module\n",
    "    * Basic example\n",
    "        * 1 pipeline with fixed parameters\n",
    "             * creating research\n",
    "             * running several repetitions of an experiment\n",
    "             * viewing research results\n",
    "             * saving and loading research\n",
    "    * Runnung experiments with different parameters aka grid\n",
    "        * 1 pipeline with variable parameters\n",
    "             * creating and viewing grids\n",
    "             * viewing filtered research results\n",
    "             \n",
    "             \n",
    "2. Complex Execution Strategies with Research Module (**You are here**)\n",
    "    * Reducing extra dataset loads\n",
    "        * 1 pipeline with root and branch + grid\n",
    "    * More complex execution strategies\n",
    "        * 2 pipelines, train & test + function + root&branch + grid\n",
    "            * adding test pipeline\n",
    "            * defining results recording frequency aka execute='%n'\n",
    "            * adding functions\n",
    "3. \n",
    "    * Cross-validation\n",
    "\n",
    "    * Performance\n",
    "        * execution tasks managing\n",
    "    * Combining it all together\n",
    "        * Super complex Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing extra dataset loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# from tensorflow import logging\n",
    "# logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from batchflow import Pipeline, B, C, V\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.tf import VGG7, VGG16\n",
    "from batchflow.research import Research, Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "ITERATIONS=10\n",
    "REPETITIONS=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous tutorial we learned how to use Research to run experimetrs multiple times and with varying parameters.\n",
    "\n",
    "Firstly we define a dataset to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST()\n",
    "train_root = mnist.train.p.run(BATCH_SIZE, shuffle=True, n_epochs=None, lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a grid of parameters whose nodes will be used to form separate experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Option('layout', ['cna', 'can']) * Option('bias', [True, False])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters can be passed to model's configs using named expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\n",
    "    'inputs': dict(images={'shape': (28, 28, 1)},\n",
    "                   labels={'classes': 10, 'transform': 'ohe', 'name': 'targets'}),\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    'common/conv/use_bias': C('bias'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we define a pipeline to run during our experiments. We initialise a pipeline variable *'loss'* to store loss on each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_template = (Pipeline()\n",
    "            .init_variable('loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', fetches='loss',\n",
    "                         feed_dict={'images': B('images'),\n",
    "                                    'labels': B('labels')},\n",
    "                         save_to=V('loss', mode='w'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define a Research that runs the *pipeline* substituting its parameters using different nodes of the *grid*, and saves values of the *'loss'* named expressions to results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research research is starting...\n",
      "Distributor has 16 jobs with 10 iterations. Totally: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [10:27<00:00,  3.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x1b6fee30208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research = (Research()\n",
    "            .add_pipeline(train_root + train_template, variables='loss')\n",
    "            .add_grid(grid))\n",
    "\n",
    "research.run(n_reps=4, n_iters=10, name='research', bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 experiments are run (4 grid nodes x 4 repetitions) each consisting of 10 iterations\n",
    "We can load results of the research and see that the table has 160 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 160 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      "repetition    160 non-null int64\n",
      "name          160 non-null object\n",
      "loss          160 non-null float64\n",
      "iteration     160 non-null int64\n",
      "layout        160 non-null object\n",
      "bias          160 non-null object\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "research.load_results().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each experiment can be divided into 2 stages: root stage that is roughly same for all experiments (for example, data loading and preprocessing) and branch stage that varies. If data preprocessing takes significant time one can use the batches generated on a root stage to feed to several branches that belong to different experiments. \n",
    "\n",
    "To do so, one should pass *root* and *branch* parameters to *add_pipeline()* and define number of branches per root via *branches* parameter of *run()*.\n",
    "\n",
    "A root with corresponding branches is called a **job**. Note that different roots produce different batches due to shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research no_extra_dataload_research is starting...\n",
      "Distributor has 2 jobs with 10 iterations. Totally: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [04:00<00:00, 12.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x1b6e7cf20b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research = (Research()\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='loss')\n",
    "            .add_grid(grid))\n",
    "\n",
    "research.run(n_reps=4, n_iters=10, branches=8, name='no_extra_dataload_research', bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scince every root now assigned to 8 branches, there are only 2 jobs.\n",
    "\n",
    "We can see that the whole research duration reduced.\n",
    "In this toy example we use only 10 iterations to make the effect of reduced dataset load more visible.\n",
    "\n",
    "The numbers of results entries is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 160 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      "repetition    160 non-null int64\n",
      "name          160 non-null object\n",
      "loss          160 non-null float64\n",
      "iteration     160 non-null int64\n",
      "layout        160 non-null object\n",
      "bias          160 non-null object\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "research.load_results().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex execution strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Option('model', [VGG7]) * Option('layout', ['cna', 'can']) #* Option('bias', [True, False])\n",
    "\n",
    "model_config={\n",
    "    #'session/config': tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.45)),\n",
    "    'inputs': dict(images={'shape': (28, 28, 1)},\n",
    "                   labels={'classes': 10, 'transform': 'ohe', 'name': 'targets'}),\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    #'common/conv/use_bias': C('bias'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('train_loss')\n",
    "            .init_model('dynamic', C('model'), 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', fetches='loss',\n",
    "                         feed_dict={'images': B('images'),\n",
    "                                    'labels': B('labels')},\n",
    "                         save_to=V('train_loss', mode='w'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root = mnist.test.p.run(BATCH_SIZE, shuffle=True, n_epochs=1, lazy=True) #Note  n_epochs=1\n",
    "test_template = (Pipeline()\n",
    "                 .init_variable('test_loss')\n",
    "                 .import_model('conv', C('import_from'))\n",
    "                 .to_array()\n",
    "                 .predict_model('conv', \n",
    "                               fetches='loss',\n",
    "                               feed_dict={'images': B('images'),\n",
    "                                          'labels': B('labels')},\n",
    "                               save_to=V('test_loss', mode='w')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EXECUTE_FREQ = '%5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='train_loss', name='train')\n",
    "            .add_pipeline(root=test_root, branch=test_template, variables='test_loss', name='test',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from='train') # Note run=True\n",
    "            .add_grid(grid))\n",
    "\n",
    "research.run(n_iters=ITERATIONS, name='my_research', bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use .add_pipeline with run=False (which is the default value) this means that the pipeline is executed batch-wise and an 'iteration' refers to processing a single batch. If we use run=True than the pipeline is executed on the whole dataset and an 'iteration' is rather an epoch.\n",
    "\n",
    "When we wish to evaluate the models performance naturally we want to execute the test pipeline on the whole validation set \n",
    "\n",
    "Here for each config from grid the train pipeline's gen_batch() is run n_iters times. After each 100-th train's gen_batch() the whole test pipeline is run and model's loss on test set is evaluated. Gathering test set loss might seem rather useless, we do it solely to demonstrate how to control multiple pipeline execution, and we will soon move to a more interesting case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = research.load_results(iterations=[4,9])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_template = (Pipeline()\n",
    "                 .init_variable('predictions')\n",
    "                 .init_variable('metrics')\n",
    "                 .import_model('conv', C('import_from'))\n",
    "                 .to_array()\n",
    "                 .predict_model('conv', \n",
    "                               fetches='predictions',\n",
    "                               feed_dict={'images': B('images'),\n",
    "                                          'labels': B('labels')},\n",
    "                               save_to=V('predictions'))\n",
    "                .gather_metrics('class', targets=B('labels'), predictions=V('predictions'), \n",
    "                                fmt='logits', axis=-1, save_to=V('metrics')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(iteration, experiment, pipeline):\n",
    "    pipeline = experiment[pipeline].pipeline\n",
    "    metrics = pipeline.get_variable('metrics')\n",
    "    return metrics.evaluate('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='train_loss', name='train_ppl')\n",
    "            .add_pipeline(root=test_root, branch=test_template, name='test_ppl',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from='train_ppl')\n",
    "            .add_function(get_accuracy, returns='accuracy', name='test_accuracy_fn', execute=TEST_EXECUTE_FREQ, pipeline='test_ppl')\n",
    "            .add_grid(grid))\n",
    "\n",
    "research.run(n_reps=1, n_iters=ITERATIONS, name='my_research', bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = research.load_results()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research my_research_31 is starting...\n",
      "Distributor has 2 jobs with 10 iterations. Totally: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:55<00:00,  2.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x1df08efac18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_on_root(iteration, experiments):\n",
    "    print(\"Running configs\", iteration)\n",
    "    \n",
    "research = (Research()\n",
    "            .add_function(function_on_root, execute=1, on_root=True)\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='train_loss', name='train')\n",
    "            .add_pipeline(root=test_root, branch=test_template, name='test',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from='train')\n",
    "            .add_function(get_accuracy, returns='accuracy', name='test_accuracy', execute=TEST_EXECUTE_FREQ, pipeline='test')\n",
    "            .add_grid(grid))\n",
    "\n",
    "research.run(n_reps=2, n_iters=ITERATIONS, branches=2, name='my_research', bar=True)\n",
    "#research.run(n_reps=1, n_iters=100, workers=2, branches=2, gpu=[2, 4, 5, 6], name='my_research', bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each worker starts in a separate process and performs one or several jobs assigned to it. Moreover if several GPU's are accessible one can pass indices of GPUs to use via *gpu* parameter.\n",
    "\n",
    "timeout - minutes, default=5\n",
    "trials default=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research my_research_32 is starting...\n",
      "Distributor has 8 jobs with 10 iterations. Totally: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [02:24<00:00,  1.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x1df06944ac8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model_config={\n",
    "    'session/config': tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.45)),\n",
    "    'inputs': dict(images={'shape': (28, 28, 1)},\n",
    "                   labels={'classes': 10, 'transform': 'ohe', 'name': 'targets'}),\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    #'common/conv/use_bias': C('bias'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('train_loss')\n",
    "            .init_model('dynamic', C('model'), 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', fetches='loss',\n",
    "                         feed_dict={'images': B('images'),\n",
    "                                    'labels': B('labels')},\n",
    "                         save_to=V('train_loss', mode='w'))\n",
    ")\n",
    "\n",
    "research = (Research()\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='train_loss', name='train_ppl',\n",
    "                          dump=TEST_EXECUTE_FREQ)\n",
    "            .add_pipeline(root=test_root, branch=test_template, name='test_ppl',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from='train_ppl')\n",
    "            .add_function(get_accuracy, returns='accuracy', name='test_accuracy_fn', \n",
    "                          execute=TEST_EXECUTE_FREQ, dump=TEST_EXECUTE_FREQ,\n",
    "                          pipeline='test_ppl')\n",
    "            .add_grid(grid))\n",
    "\n",
    "research.run(n_reps=4, n_iters=ITERATIONS, name='my_research', bar=True, workers=2, gpu=[0], timeout=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
