{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Research Module Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with some useful imports and constant definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../..')\n",
    "\n",
    "from batchflow import Pipeline, B, C, V, D, L\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.tf import VGG7, VGG16\n",
    "from batchflow.research import Research, Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "ITERATIONS=10\n",
    "TEST_EXECUTE_FREQ=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_previous_results(res_name):\n",
    "    if os.path.exists(res_name):\n",
    "        shutil.rmtree(res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Extra Dataset Loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Research Sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous tutorial we learned how to use Research to run experimetrs multiple times and with varying parameters.\n",
    "\n",
    "Firstly we define a dataset to work with and a pipeline that reads this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST()\n",
    "train_root = mnist.train.p.run_later(BATCH_SIZE, shuffle=True, n_epochs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a grid of parameters whose nodes will be used to form separate experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = Option('layout', ['cna', 'can']) * Option('bias', [True, False])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters can be passed to model's configs using named expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': D('num_classes'),\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    'common/conv/use_bias': C('bias'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we define a pipeline to run during our experiments. We initialise a pipeline variable `'loss'` to store loss on each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_template = (Pipeline()\n",
    "            .init_variable('loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('loss', mode='w'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each research is assigned with a name and writes its results to a folder with this name. The names must be unique, so if one attempts to run a research with a name that already exists, an error will be thrown. In the cell below we clear the results of previous research runs so as to allow multiple runs of a research. This is done solely for purposes of ths tutorial and should not be done in real work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_name = 'simple_research'\n",
    "clear_previous_results(res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define a Research that runs the pipeline substituting its parameters using different nodes of the `grid`, and saves values of the `'loss'` named expressions to results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research simple_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 160/160.0 [05:54<00:00,  2.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7fe1c82d66d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research = (Research()\n",
    "            .add_pipeline(train_root + train_template, variables='loss')\n",
    "            .init_domain(domain, n_reps=4))\n",
    "\n",
    "research.run(n_iters=10, name=res_name, bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 experiments are run (4 grid nodes x 4 repetitions) each consisting of 10 iterations.\n",
    "\n",
    "We can load results of the research and see that the table has 160 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160 entries, 0 to 159\n",
      "Data columns (total 7 columns):\n",
      "bias            160 non-null object\n",
      "iteration       160 non-null int64\n",
      "layout          160 non-null object\n",
      "loss            160 non-null float64\n",
      "name            160 non-null object\n",
      "repetition      160 non-null int64\n",
      "sample_index    160 non-null int64\n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "research.load_results().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branches: Reducing Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each experiment can be divided into 2 stages: root stage that is roughly same for all experiments (for example, data loading and preprocessing) and branch stage that varies. If data loading and preprocessing take significant time one can use the batches generated on a single root stage to feed to several branches that belong to different experiments. \n",
    "\n",
    "For example, if you want to test 4 different models, and yor workflow includes some complicated data preprocessing and augmentation that is done separatey for each model, you may want to do preprocessing and augmentation once and feed resulting batches of data to all these 4 models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](img/Branch_Root_Figure_crop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure above shows the difference. \n",
    "\n",
    "On the left, simple workflow is shown. Same steps of common preprocessing are performed 4 times, and the batches that are generated after different runs of common stages are also different due to shuffling and possible randomisation inside common steps.\n",
    "\n",
    "On the right, common steps are performed once on root stage and the very same batches are passed to different branches. This has the advantage of reducing extra computations but it also reduces variability becauce all models get exactly same pieces of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform root-branch division, one should pass `root` and `branch` parameters to `add_pipeline()` and define number of branches per root via `branches` parameter of `run()`.\n",
    "\n",
    "A root with corresponding branches is called a **job**. Note that different roots still produce different batches.\n",
    "\n",
    "One constraint when using branches is that branch pipelines do not calculate dataset variables properly, so we have to redefine `model_config` and `train_template` and hard-code `'inputs/labels/classes'` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research no_extra_dataload_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 20/20.0 [02:04<00:00,  6.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7fe1ad886518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config={\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': 10,\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    'common/conv/use_bias': C('bias'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('loss', mode='w'))\n",
    ")\n",
    "\n",
    "res_name = 'no_extra_dataload_research'\n",
    "clear_previous_results(res_name)\n",
    "    \n",
    "research = (Research()\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='loss')\n",
    "            .init_domain(domain, n_reps=4))\n",
    "\n",
    "research.run(n_iters=10, branches=8, name=res_name, bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scince every root is now assigned to 8 branches, there are only 2 jobs.\n",
    "\n",
    "We can see that the whole research duration reduced.\n",
    "In this toy example we use only 10 iterations to make the effect of reduced dataset load more visible.\n",
    "\n",
    "The numbers of results entries is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research.load_results().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions on Root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each job has several branches, they are all executed in parallel threads. To run a function on root, one should add it with `on_root=True`.\n",
    "\n",
    "Functions on root have required parameters `iteration` and `experiments` and optional keyword parameters. They are not allowed to return anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research on_root_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  50%|█████     | 10/20.0 [01:04<01:04,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 20/20.0 [02:02<00:00,  6.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7f93cf54f4a8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_name = 'on_root_research'\n",
    "clear_previous_results(res_name)\n",
    "\n",
    "def function_on_root():\n",
    "    print('on root')\n",
    "    \n",
    "research = (Research()\n",
    "            .add_callable(function_on_root, execute=\"#0\", on_root=True)\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='loss')\n",
    "            .init_domain(domain, n_reps=4)\n",
    "           )\n",
    "\n",
    "research.run(branches=8, n_iters=ITERATIONS, name=res_name, bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research can ran experiments in parallel if number of workers if defined in `workers` parameter. \n",
    "Each worker starts in a separate process and performs one or several jobs assigned to it. Moreover if several GPU's are accessible one can pass indices of GPUs to use via `gpu` parameter.\n",
    "\n",
    "Following parameters are also useful to control research execution:\n",
    "* `timeout` in `run` specifies time in minutes to kill non-responding job, default value is 5\n",
    "* `trials` in `run` specifies number of attempts to restart a job, default=2\n",
    "* `dump` in `add_pipeline`, `add_function` and `get_metrics` tells how often results are written to disk and cleared. By default results are dumped on the last iteration, but if they consume too much memory one may want to do it more often. The format is same as `execute`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research faster_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59400 11756 16042 15449 56852  8029  8834 47440 10212 17029 28135  5086\n",
      " 19477 57745 14349 38152 35071 36933 31905 42255 59531 17203  3465 57459\n",
      " 33842 24094 38011 23619 28137 26768 35830  5822 16113 20211  9602 37468\n",
      " 36774  6010 19633 51276 39398  8979 53129 44961 51012 40774 30908 35444\n",
      " 48577  5342 14506 15058  4247   290 18814 19138 52040  4282  5134 45542\n",
      " 42744 22772 50869 28513]\n",
      "[59400 11756 16042 15449 56852  8029  8834 47440 10212 17029 28135  5086\n",
      " 19477 57745 14349 38152 35071 36933 31905 42255 59531 17203  3465 57459\n",
      " 33842 24094 38011 23619 28137 26768 35830  5822 16113 20211  9602 37468\n",
      " 36774  6010 19633 51276 39398  8979 53129 44961 51012 40774 30908 35444\n",
      " 48577  5342 14506 15058  4247   290 18814 19138 52040  4282  5134 45542\n",
      " 42744 22772 50869 28513]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   0%|          | 0/80.0 [00:34<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4556  3378 32565 36973 37290  2786 16494 18789 44965 54033 14938 13555\n",
      " 43571 50290 47946 36561   401 34573  6162 11577 17416 53151  7308 49409\n",
      "  8755 32147 22989 52989 32164 56206   689  2536  5104 20017  5023 32035\n",
      "   279 39282 20337 35280 34043 29703  2474  5682 55842 51088 53508  8546\n",
      " 17647 58006 38078 23696 41440 26315 25822 29635 52385 23066  4637 29766\n",
      " 37798   933 25301 36184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   0%|          | 0/80.0 [00:34<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   1%|▏         | 1/80.0 [00:34<45:24, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18180 49899 51133  7394 41203  9909 18694 10177 24075 35206 57455 50629\n",
      " 27423  6138 51022 39779  5945 59172 28725 43675 28405 48685 10126 16964\n",
      " 50896  7754  8927 20523 25095 27351 13845 29929 47108  2999 37651 23462\n",
      " 11627 16175  7045 37874 58513 27901  3571 23358 48132  3268 24670  2129\n",
      "   489 55485 39481 43726 59364 23925 59742 19776  6968 34309 52764 54950\n",
      " 57530 20511 12534  7395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   1%|▏         | 1/80.0 [00:34<45:24, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   2%|▎         | 2/80.0 [00:34<22:27, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34326 39469 25775  3141 22680 57319 54973 16193 14344 15837 39970  2094\n",
      " 21803 49753 56460 15429 38585 15454  2247 36342  5519 44894 30036 13117\n",
      " 18164 17202 46668 58133 31709 58401 53376 56935 52134 25859 50515 43860\n",
      " 41725 55109 14648  4265  1741 43491 19466 56317 16622 42352 49371  5538\n",
      " 48009 58801 19211 35248 29281 26961 45159 45499  5173 56481 32127 33863\n",
      " 49477 41290 22162 52616]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   2%|▎         | 2/80.0 [00:34<22:27, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   4%|▍         | 3/80.0 [00:34<14:47, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23124 39952 53329 38081 40436 59120 22489 24200 52818 38646  8190 26394\n",
      " 54781  5662 14403 44670 38060 51070 22494 22548 16802 57114  8504 47769\n",
      " 10734 43241 13163 42182 56104 42615 46294 54268 14827 47876 15712 34750\n",
      " 43457 25255 58903  4194 54692 40392 45047 14965 36756  5515 26687  1966\n",
      " 42403 47164 10673 13688 42936 29611 12822  5130  9651 23399 26412 18908\n",
      " 30872 45633 48618 41976]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   4%|▍         | 3/80.0 [00:34<14:48, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   5%|▌         | 4/80.0 [00:34<10:58,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56859 41470 44467 13140 55231 55281 24435  1459 26516 11980  9019 28258\n",
      " 36691 30416 29339  5397 42130 31297 12409 16060 25602 55382 59792 21797\n",
      " 21011 35739 58785 19933 16530 48820 40562 18641 32881 16780 31690  3051\n",
      "  4682 54450 31474 21854 49770  6629 31437 56096 42018   350 58225 55257\n",
      " 49372 26588 31605 25763   386 27828   358 25561 18001 37162 27370 17468\n",
      " 27725 33856 37118  7484]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   5%|▌         | 4/80.0 [00:34<10:58,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   6%|▋         | 5/80.0 [00:34<08:40,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1307  9683 16254  2828 33934  4253 32820 36692 17465 51062 30286 52921\n",
      " 32916 52441 36616  9054 39646 20237 33364 52819   456 28767 28287 19261\n",
      " 31949 54035 23345 14249 44057 19036 50019 53248 40304 40717 55005 59965\n",
      "  1182  5504  4544 23366 24008 55118 12956 52063 36579 39199 43095  4605\n",
      " 14622 24577 18916 56808   860   452 25204  1070 17854 26012 59452 10054\n",
      " 29403 39072 17963 53338]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   6%|▋         | 5/80.0 [00:34<08:40,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   8%|▊         | 6/80.0 [00:34<07:08,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52364 57833 44585 48759 51737 41924 45050 40495 24501 19869 46758 24441\n",
      " 29496  3410 41736 41001 48022 34086 59737 12366 34523 51325 28921 37333\n",
      " 35608 35946 48186 51536 12855  9402 53727 29404 20652  1233  8984 27455\n",
      " 47373 53405 44725 52135 16396 31738  8780  5344 26667   706  5299 12202\n",
      " 19920 28813 23924 34345  2690 32353 48762 41539  2504 20912 10709 21807\n",
      " 48788  9879 34926  9827]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   8%|▊         | 6/80.0 [00:34<07:08,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   9%|▉         | 7/80.0 [00:34<06:02,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9861 16878 19590 13949 48003 23075 57446    92 46743 53511 16578 11325\n",
      " 20510 37851  1448 26251 55185 17389 19361 40455 34727  3351 52774 50900\n",
      "  9091 50091 51939 36056 49514 15426  1065 30519 27253 16525 54532 21312\n",
      " 44777 13707 44404 15491  1156  5573 50051 47917 30867  6659 48679  2640\n",
      " 20975  4721 11189 46037 22332 19862 49018 28640 48967 39907 33512 42354\n",
      " 58579 24037 12577 36700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:   9%|▉         | 7/80.0 [00:34<06:02,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  10%|█         | 8/80.0 [00:34<05:13,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28387 57135 21729 33336 41787 30907 47578 58714 16360 39759 26256  7266\n",
      " 51388 54389 20224 31088 17053 47695 25499 39564 23730 33941 31613 33896\n",
      " 24705 45540 56194  8643 50856 28890 31781 45544 13775 33260 34640 32708\n",
      " 25965 26668 13716 33051 52619 44901 53968 31767 46194 51593 57111 18749\n",
      " 39854 45598 27780 46569 36540 54527 50284 54605 49702 37699  2248 30314\n",
      " 20850 54841  8748 53407]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  10%|█         | 8/80.0 [00:34<05:13,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  12%|█▎        | 10/80.0 [00:39<04:37,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4556  3378 32565 36973 37290  2786 16494 18789 44965 54033 14938 13555\n",
      " 43571 50290 47946 36561   401 34573  6162 11577 17416 53151  7308 49409\n",
      "  8755 32147 22989 52989 32164 56206   689  2536  5104 20017  5023 32035\n",
      "   279 39282 20337 35280 34043 29703  2474  5682 55842 51088 53508  8546\n",
      " 17647 58006 38078 23696 41440 26315 25822 29635 52385 23066  4637 29766\n",
      " 37798   933 25301 36184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  12%|█▎        | 10/80.0 [00:39<04:39,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  12%|█▎        | 10/80.0 [00:39<04:39,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18180 49899 51133  7394 41203  9909 18694 10177 24075 35206 57455 50629\n",
      " 27423  6138 51022 39779  5945 59172 28725 43675 28405 48685 10126 16964\n",
      " 50896  7754  8927 20523 25095 27351 13845 29929 47108  2999 37651 23462\n",
      " 11627 16175  7045 37874 58513 27901  3571 23358 48132  3268 24670  2129\n",
      "   489 55485 39481 43726 59364 23925 59742 19776  6968 34309 52764 54950\n",
      " 57530 20511 12534  7395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  12%|█▎        | 10/80.0 [00:40<04:41,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34326 39469 25775  3141 22680 57319 54973 16193 14344 15837 39970  2094\n",
      " 21803 49753 56460 15429 38585 15454  2247 36342  5519 44894 30036 13117\n",
      " 18164 17202 46668 58133 31709 58401 53376 56935 52134 25859 50515 43860\n",
      " 41725 55109 14648  4265  1741 43491 19466 56317 16622 42352 49371  5538\n",
      " 48009 58801 19211 35248 29281 26961 45159 45499  5173 56481 32127 33863\n",
      " 49477 41290 22162 52616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  12%|█▎        | 10/80.0 [00:40<04:42,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23124 39952 53329 38081 40436 59120 22489 24200 52818 38646  8190 26394\n",
      " 54781  5662 14403 44670 38060 51070 22494 22548 16802 57114  8504 47769\n",
      " 10734 43241 13163 42182 56104 42615 46294 54268 14827 47876 15712 34750\n",
      " 43457 25255 58903  4194 54692 40392 45047 14965 36756  5515 26687  1966\n",
      " 42403 47164 10673 13688 42936 29611 12822  5130  9651 23399 26412 18908\n",
      " 30872 45633 48618 41976][56859 41470 44467 13140 55231 55281 24435  1459 26516 11980  9019 28258\n",
      " 36691 30416 29339  5397 42130 31297 12409 16060 25602 55382 59792 21797\n",
      " 21011 35739 58785 19933 16530 48820 40562 18641 32881 16780 31690  3051\n",
      "  4682 54450 31474 21854 49770  6629 31437 56096 42018   350 58225 55257\n",
      " 49372 26588 31605 25763   386 27828   358 25561 18001 37162 27370 17468\n",
      " 27725 33856 37118  7484]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  12%|█▎        | 10/80.0 [00:40<04:44,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 1307  9683 16254  2828 33934  4253 32820 36692 17465 51062 30286 52921\n",
      " 32916 52441 36616  9054 39646 20237 33364 52819   456 28767 28287 19261\n",
      " 31949 54035 23345 14249 44057 19036 50019 53248 40304 40717 55005 59965\n",
      "  1182  5504  4544 23366 24008 55118 12956 52063 36579 39199 43095  4605\n",
      " 14622 24577 18916 56808   860   452 25204  1070 17854 26012 59452 10054\n",
      " 29403 39072 17963 53338]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  12%|█▎        | 10/80.0 [00:40<04:45,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[52364 57833 44585 48759 51737 41924 45050 40495 24501 19869 46758 24441\n",
      " 29496  3410 41736 41001 48022 34086 59737 12366 34523 51325 28921 37333\n",
      " 35608 35946 48186 51536 12855  9402 53727 29404 20652  1233  8984 27455\n",
      " 47373 53405 44725 52135 16396 31738  8780  5344 26667   706  5299 12202\n",
      " 19920 28813 23924 34345  2690 32353 48762 41539  2504 20912 10709 21807\n",
      " 48788  9879 34926  9827]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  14%|█▍        | 11/80.0 [00:40<04:17,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 9861 16878 19590 13949 48003 23075 57446    92 46743 53511 16578 11325\n",
      " 20510 37851  1448 26251 55185 17389 19361 40455 34727  3351 52774 50900\n",
      "  9091 50091 51939 36056 49514 15426  1065 30519 27253 16525 54532 21312\n",
      " 44777 13707 44404 15491  1156  5573 50051 47917 30867  6659 48679  2640\n",
      " 20975  4721 11189 46037 22332 19862 49018 28640 48967 39907 33512 42354\n",
      " 58579 24037 12577 36700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  14%|█▍        | 11/80.0 [00:41<04:18,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[28387 57135 21729 33336 41787 30907 47578 58714 16360 39759 26256  7266\n",
      " 51388 54389 20224 31088 17053 47695 25499 39564 23730 33941 31613 33896\n",
      " 24705 45540 56194  8643 50856 28890 31781 45544 13775 33260 34640 32708\n",
      " 25965 26668 13716 33051 52619 44901 53968 31767 46194 51593 57111 18749\n",
      " 39854 45598 27780 46569 36540 54527 50284 54605 49702 37699  2248 30314\n",
      " 20850 54841  8748 53407]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  14%|█▍        | 11/80.0 [00:41<04:19,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  25%|██▌       | 20/80.0 [00:45<02:17,  2.30s/it]"
     ]
    }
   ],
   "source": [
    "from batchflow.research import ResearchPipeline as RP\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "model_config={\n",
    "    'device': C('device'), # it's technical parameter for TFModel\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': 10,\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    'common/conv/use_bias': C('bias'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('train_loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('train_loss', mode='w'))\n",
    ")\n",
    "\n",
    "test_root = mnist.test.p.run_later(BATCH_SIZE, shuffle=True, n_epochs=1) #Note  n_epochs=1\n",
    "\n",
    "test_template = (Pipeline()\n",
    "                 .init_variable('predictions')\n",
    "                 .init_variable('metrics')\n",
    "                 .import_model('conv', C('import_from'))\n",
    "                 .to_array()\n",
    "                 .predict_model('conv', \n",
    "                                images=B('images'), labels=B('labels'),\n",
    "                                fetches='predictions', save_to=V('predictions'))\n",
    "                 .gather_metrics('class', targets=B('labels'), predictions=V('predictions'), \n",
    "                                fmt='logits', axis=-1, save_to=V('metrics')))\n",
    "\n",
    "research = (Research()\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='train_loss', name='train_ppl',\n",
    "                          dump=TEST_EXECUTE_FREQ)\n",
    "            .add_pipeline(root=test_root, branch=test_template, name='test_ppl',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from=RP('train_ppl'))\n",
    "            .get_metrics(pipeline='test_ppl', metrics_var='metrics', metrics_name='accuracy',\n",
    "                         returns='accuracy', \n",
    "                         execute=TEST_EXECUTE_FREQ,\n",
    "                         dump=TEST_EXECUTE_FREQ,)\n",
    "            .init_domain(domain, n_reps=4))\n",
    "\n",
    "res_name = 'faster_research'\n",
    "clear_previous_results(res_name)\n",
    "\n",
    "research.run(n_iters=ITERATIONS, name=res_name, bar=True, \n",
    "             branches=2, workers=2, devices=[0, 1], \n",
    "             timeout=2, trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140 entries, 0 to 139\n",
      "Data columns (total 8 columns):\n",
      "accuracy        0 non-null float64\n",
      "bias            140 non-null object\n",
      "iteration       140 non-null int64\n",
      "layout          140 non-null object\n",
      "name            140 non-null object\n",
      "repetition      140 non-null int64\n",
      "sample_index    140 non-null int64\n",
      "train_loss      140 non-null float64\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "results = research.load_results()\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easyly perform cross-validation with Research\n",
    "\n",
    "Firstly we will define a dataset: we will use train subset of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST().train\n",
    "mnist_train.cv_split(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our train and test pipelines. When performing cross-validation, Research will automatically split the dataset given and feed the folds to pipelines, so we will rather define pipeline templates that will wait for a dataset to work with. In contrast with previous tutorials we are adding `run` method to pipeline templates, not dataset pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': D('num_classes'),\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "}\n",
    "\n",
    "train_template = (ds.p\n",
    "            .cv_fold(C('fold'), 'train')\n",
    "            .init_variable('train_loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('train_loss', mode='w'))\n",
    "            .run_later(BATCH_SIZE, shuffle=True, n_epochs=None))\n",
    "\n",
    "test_template = (Pipeline()\n",
    "                 .cv_fold(C('fold'), 'test')\n",
    "                 .init_variable('predictions')\n",
    "                 .init_variable('metrics')\n",
    "                 .import_model('conv', C('import_from'))\n",
    "                 .to_array()\n",
    "                 .predict_model('conv', \n",
    "                                images=B('images'), labels=B('labels'),\n",
    "                                fetches='predictions', save_to=V('predictions'))\n",
    "                 .gather_metrics('class', targets=B('labels'), predictions=V('predictions'), \n",
    "                                fmt='logits', axis=-1, save_to=V('metrics'))\n",
    "                 .run_later(BATCH_SIZE, shuffle=True, n_epochs=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now defining our Research object. To use cross-validation we should pass `dataset` and `part` parameters to `add_pipeline` methods. We will use train subset of MNIST `mnist_train` created above, so we pass `dataset=mnist_train`. This subset was also split on train and test parts when created, so we pass `part='train'` when adding train pipeline and `part='test'` when adding test pipeline. We don't pass any dataset to `root` explicitely scince this is now Research that cares for data. \n",
    "\n",
    "Next, we call `run` with `n_splits` parameter that defines the number of cv folds. We can also pass `shuffle` to specify whether to shuffle the dataset before splitting. `shuffle` can be bool, int, `numpy.random.RandomState` or callable, its default value is *False* which means no shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research cv_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 60/60.0 [03:15<00:00,  3.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7f395babeb70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain = Option('layout', ['cna', 'can']) * Option('fold', [0, 1, 2])\n",
    "\n",
    "research = (Research()\n",
    "            .add_pipeline(train_template, dataset=mnist_train, variables='train_loss', name='train_ppl')\n",
    "            .add_pipeline(test_template, dataset=mnist_train, name='test_ppl',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from='train_ppl')\n",
    "            .get_metrics(pipeline='test_ppl', metrics_var='metrics', metrics_name='accuracy', returns='accuracy', \n",
    "                         execute=TEST_EXECUTE_FREQ)\n",
    "            .init_domain(domain))\n",
    "\n",
    "res_name = 'cv_research'\n",
    "clear_previous_results(res_name)\n",
    "    \n",
    "research.run(n_iters=ITERATIONS, name=res_name, bar=True, workers=1, devices=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load results, specifying which folds to get if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fold</th>\n",
       "      <th>iteration</th>\n",
       "      <th>layout</th>\n",
       "      <th>name</th>\n",
       "      <th>repetition</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>can</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.914540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>cna</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.068651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>can</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>can</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cna</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.761201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy fold  iteration layout       name  repetition  sample_index  \\\n",
       "15       NaN    0        5.0    can  train_ppl           0           0.0   \n",
       "5        NaN    0        5.0    cna  train_ppl           0           0.0   \n",
       "12       NaN    0        2.0    can  train_ppl           0           0.0   \n",
       "17       NaN    0        7.0    can  train_ppl           0           0.0   \n",
       "2        NaN    0        2.0    cna  train_ppl           0           0.0   \n",
       "\n",
       "    train_loss  \n",
       "15    0.914540  \n",
       "5     1.068651  \n",
       "12    1.486790  \n",
       "17    0.721579  \n",
       "2     1.761201  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = research.load_results(fold=0)\n",
    "results.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "test_results = research.load_results(names= 'test_ppl_metrics', use_alias=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for i, (config, df) in enumerate(test_results.groupby('config')):\n",
    "    x, y = i//2, i%2\n",
    "    df.pivot(index='iteration', columns='cv_split', values='accuracy').plot(ax=ax[y])\n",
    "    ax[y].set_title(config)\n",
    "    ax[y].set_xlabel('iteration')\n",
    "    ax[y].set_ylabel('accuracy')\n",
    "    ax[y].grid(True)\n",
    "    ax[y].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation with Extra Performance Settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still use branch-root division to preprocess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': 10,\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('train_loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('train_loss', mode='w'))\n",
    "            .run_later(BATCH_SIZE, shuffle=True, n_epochs=None))\n",
    "\n",
    "augmentation_pipeline = Pipeline().salt(p=0.5).run_later(BATCH_SIZE, shuffle=True, n_epochs=None)\n",
    "\n",
    "research = (Research()\n",
    "            .add_pipeline(root=augmentation_pipeline, branch=train_template,\n",
    "                          dataset=mnist_train, part='train', \n",
    "                          variables='train_loss', name='train_ppl')\n",
    "            .add_pipeline(test_template, dataset=mnist_train, part='test', name='test_ppl',\n",
    "                          execute=TEST_EXECUTE_FREQ, run=True, import_from='train_ppl')\n",
    "            .get_metrics(pipeline='test_ppl', metrics_var='metrics', metrics_name='accuracy', returns='accuracy', \n",
    "                         execute=TEST_EXECUTE_FREQ)\n",
    "            .add_grid(grid))\n",
    "\n",
    "res_name = 'cv_branches_research'\n",
    "clear_previous_results(res_name)\n",
    "\n",
    "research.run(n_iters=ITERATIONS,\n",
    "             n_splits=3, shuffle=True,\n",
    "             workers=2, gpu=[5,6], \n",
    "             branches=2, \n",
    "             name=res_name, bar=True)\n",
    "\n",
    "research.load_results().info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
