{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Research Module Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with some useful imports and constant definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../..')\n",
    "\n",
    "from batchflow import Pipeline, B, C, V, D, L\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.tf import VGG7, VGG16\n",
    "from batchflow.research import Research, Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "ITERATIONS=1000\n",
    "TEST_EXECUTE_FREQ=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_previous_results(res_name):\n",
    "    if os.path.exists(res_name):\n",
    "        shutil.rmtree(res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Extra Dataset Loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Research Sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous tutorial we learned how to use Research to run experimetrs multiple times and with varying parameters.\n",
    "\n",
    "Firstly we define a dataset to work with and a pipeline that reads this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST()\n",
    "train_root = mnist.train.p.run_later(BATCH_SIZE, shuffle=True, n_epochs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a grid of parameters whose nodes will be used to form separate experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = Option('layout', ['cna', 'can']) * Option('bias', [True, False])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters can be passed to model's configs using named expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': D('num_classes'),\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    'common/conv/use_bias': C('bias'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we define a pipeline to run during our experiments. We initialise a pipeline variable `'loss'` to store loss on each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_template = (Pipeline()\n",
    "            .init_variable('loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('loss', mode='w'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each research is assigned with a name and writes its results to a folder with this name. The names must be unique, so if one attempts to run a research with a name that already exists, an error will be thrown. In the cell below we clear the results of previous research runs so as to allow multiple runs of a research. This is done solely for purposes of ths tutorial and should not be done in real work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_name = 'simple_research'\n",
    "clear_previous_results(res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define a Research that runs the pipeline substituting its parameters using different nodes of the `grid`, and saves values of the `'loss'` named expressions to results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research simple_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 160/160.0 [05:59<00:00,  2.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7fde4a4e21d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research = (Research()\n",
    "            .add_pipeline(train_root + train_template, variables='loss')\n",
    "            .init_domain(domain, n_reps=4))\n",
    "\n",
    "research.run(n_iters=10, name=res_name, bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 experiments are run (4 grid nodes x 4 repetitions) each consisting of 10 iterations.\n",
    "\n",
    "We can load results of the research and see that the table has 160 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160 entries, 0 to 159\n",
      "Data columns (total 7 columns):\n",
      "bias            160 non-null object\n",
      "iteration       160 non-null int64\n",
      "layout          160 non-null object\n",
      "loss            160 non-null float64\n",
      "name            160 non-null object\n",
      "repetition      160 non-null int64\n",
      "sample_index    160 non-null int64\n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "research.load_results().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branches: Reducing Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each experiment can be divided into 2 stages: root stage that is roughly same for all experiments (for example, data loading and preprocessing) and branch stage that varies. If data loading and preprocessing take significant time one can use the batches generated on a single root stage to feed to several branches that belong to different experiments. \n",
    "\n",
    "For example, if you want to test 4 different models, and yor workflow includes some complicated data preprocessing and augmentation that is done separatey for each model, you may want to do preprocessing and augmentation once and feed resulting batches of data to all these 4 models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](img/Branch_Root_Figure_crop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure above shows the difference. \n",
    "\n",
    "On the left, simple workflow is shown. Same steps of common preprocessing are performed 4 times, and the batches that are generated after different runs of common stages are also different due to shuffling and possible randomisation inside common steps.\n",
    "\n",
    "On the right, common steps are performed once on root stage and the very same batches are passed to different branches. This has the advantage of reducing extra computations but it also reduces variability becauce all models get exactly same pieces of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform root-branch division, one should pass `root` and `branch` parameters to `add_pipeline()` and define number of branches per root via `branches` parameter of `run()`.\n",
    "\n",
    "A root with corresponding branches is called a **job**. Note that different roots still produce different batches.\n",
    "\n",
    "One constraint when using branches is that branch pipelines do not calculate dataset variables properly, so we have to redefine `model_config` and `train_template` and hard-code `'inputs/labels/classes'` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research no_extra_dataload_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 20/20.0 [02:04<00:00,  6.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7fde3eadd390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config={\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': 10,\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    'common/conv/use_bias': C('bias'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('loss', mode='w'))\n",
    ")\n",
    "\n",
    "res_name = 'no_extra_dataload_research'\n",
    "clear_previous_results(res_name)\n",
    "    \n",
    "research = (Research()\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='loss')\n",
    "            .init_domain(domain, n_reps=4))\n",
    "\n",
    "research.run(n_iters=10, branches=8, name=res_name, bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scince every root is now assigned to 8 branches, there are only 2 jobs.\n",
    "\n",
    "We can see that the whole research duration reduced.\n",
    "In this toy example we use only 10 iterations to make the effect of reduced dataset load more visible.\n",
    "\n",
    "The numbers of results entries is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160 entries, 0 to 159\n",
      "Data columns (total 7 columns):\n",
      "bias            160 non-null object\n",
      "iteration       160 non-null int64\n",
      "layout          160 non-null object\n",
      "loss            160 non-null float64\n",
      "name            160 non-null object\n",
      "repetition      160 non-null int64\n",
      "sample_index    160 non-null int64\n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "research.load_results().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions on Root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each job has several branches, they are all executed in parallel threads. To run a function on root, one should add it with `on_root=True`.\n",
    "\n",
    "Functions on root have required parameters `iteration` and `experiments` and optional keyword parameters. They are not allowed to return anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research on_root_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0:  50%|█████     | 1000/2000.0 [03:48<03:48,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 2000/2000.0 [07:26<00:00,  4.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7fdf58411e48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_name = 'on_root_research'\n",
    "clear_previous_results(res_name)\n",
    "\n",
    "def function_on_root():\n",
    "    print('on root')\n",
    "    \n",
    "research = (Research()\n",
    "            .add_callable(function_on_root, execute=\"#0\", on_root=True)\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='loss')\n",
    "            .init_domain(domain, n_reps=4)\n",
    "           )\n",
    "\n",
    "research.run(branches=8, n_iters=ITERATIONS, name=res_name, bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research can ran experiments in parallel if number of workers if defined in `workers` parameter. \n",
    "Each worker starts in a separate process and performs one or several jobs assigned to it. Moreover if several GPU's are accessible one can pass indices of GPUs to use via `devices` parameter.\n",
    "\n",
    "Following parameters are also useful to control research execution:\n",
    "* `timeout` in `run` specifies time in minutes to kill non-responding job, default value is 5\n",
    "* `trials` in `run` specifies number of attempts to restart a job, default=2\n",
    "* `dump` in `add_pipeline`, `add_callable` and `get_metrics` tells how often results are written to disk and cleared. By default results are dumped on the last iteration, but if they consume too much memory one may want to do it more often. The format is same as `execute`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research faster_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 8000/8000.0 [31:07<00:00,  4.28it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7fdf24f22ac8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from batchflow.research import ResearchPipeline as RP\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "model_config={\n",
    "    'device': C('device'), # it's technical parameter for TFModel\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': 10,\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "    'common/conv/use_bias': C('bias'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('train_loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('train_loss', mode='w'))\n",
    ")\n",
    "\n",
    "test_root = mnist.test.p.run_later(BATCH_SIZE, shuffle=True, n_epochs=1) #Note  n_epochs=1\n",
    "\n",
    "test_template = (Pipeline()\n",
    "                 .init_variable('predictions')\n",
    "                 .init_variable('metrics')\n",
    "                 .import_model('conv', C('import_from'))\n",
    "                 .to_array()\n",
    "                 .predict_model('conv', \n",
    "                                images=B('images'), labels=B('labels'),\n",
    "                                fetches='predictions', save_to=V('predictions'))\n",
    "                 .gather_metrics('class', targets=B('labels'), predictions=V('predictions'), \n",
    "                                fmt='logits', axis=-1, save_to=V('metrics')))\n",
    "\n",
    "research = (Research()\n",
    "            .add_pipeline(root=train_root, branch=train_template, variables='train_loss', name='train_ppl',\n",
    "                          dump=TEST_EXECUTE_FREQ)\n",
    "            .add_pipeline(root=test_root, branch=test_template, name='test_ppl',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from=RP('train_ppl'))\n",
    "            .get_metrics(pipeline='test_ppl', metrics_var='metrics', metrics_name='accuracy',\n",
    "                         returns='accuracy', \n",
    "                         execute=TEST_EXECUTE_FREQ,\n",
    "                         dump=TEST_EXECUTE_FREQ,)\n",
    "            .init_domain(domain, n_reps=4))\n",
    "\n",
    "res_name = 'faster_research'\n",
    "clear_previous_results(res_name)\n",
    "\n",
    "research.run(n_iters=ITERATIONS, name=res_name, bar=True, \n",
    "             branches=2, workers=2, devices=[0, 1], \n",
    "             timeout=2, trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17600 entries, 0 to 17599\n",
      "Data columns (total 8 columns):\n",
      "accuracy        1600 non-null float64\n",
      "bias            17600 non-null object\n",
      "iteration       17600 non-null int64\n",
      "layout          17600 non-null object\n",
      "name            17600 non-null object\n",
      "repetition      17600 non-null int64\n",
      "sample_index    17600 non-null int64\n",
      "train_loss      16000 non-null float64\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "results = research.load_results()\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easyly perform cross-validation with Research\n",
    "\n",
    "Firstly we will define a dataset: we will use train subset of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST().train\n",
    "mnist_train.cv_split(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our train and test pipelines. To perform cross-validation, you can define train and test datasets as `mnist_train.CV(C('fold')).train` and `mnist_test.CV(C('fold')).test`, correspondingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': D('num_classes'),\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('train_loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('train_loss', mode='w'))\n",
    "            .run_later(BATCH_SIZE, shuffle=True, n_epochs=None)) << mnist_train.CV(C('fold')).train\n",
    "\n",
    "test_template = (Pipeline()\n",
    "                 .init_variable('predictions')\n",
    "                 .init_variable('metrics')\n",
    "                 .import_model('conv', C('import_from'))\n",
    "                 .to_array()\n",
    "                 .predict_model('conv', \n",
    "                                images=B('images'), labels=B('labels'),\n",
    "                                fetches='predictions', save_to=V('predictions'))\n",
    "                 .gather_metrics('class', targets=B('labels'), predictions=V('predictions'), \n",
    "                                fmt='logits', axis=-1, save_to=V('metrics'))\n",
    "                 .run_later(BATCH_SIZE, shuffle=True, n_epochs=1))  << mnist_train.CV(C('fold')).test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then multiply your `Domain` by `Option('fold', [0, 1, 2])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research cv_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 6000/6000.0 [1:47:55<00:00,  1.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7fdf1e96dc50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain = Option('layout', ['cna', 'can']) * Option('fold', [0, 1, 2])\n",
    "\n",
    "research = (Research()\n",
    "            .add_pipeline(train_template, dataset=mnist_train, variables='train_loss', name='train_ppl')\n",
    "            .add_pipeline(test_template, dataset=mnist_train, name='test_ppl',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from=RP('train_ppl'))\n",
    "            .get_metrics(pipeline='test_ppl', metrics_var='metrics', metrics_name='accuracy', returns='accuracy', \n",
    "                         execute=TEST_EXECUTE_FREQ)\n",
    "            .init_domain(domain))\n",
    "\n",
    "res_name = 'cv_research'\n",
    "clear_previous_results(res_name)\n",
    "    \n",
    "research.run(n_iters=ITERATIONS, name=res_name, bar=True, workers=1, devices=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load results, specifying which folds to get if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fold</th>\n",
       "      <th>iteration</th>\n",
       "      <th>layout</th>\n",
       "      <th>name</th>\n",
       "      <th>repetition</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>454</td>\n",
       "      <td>can</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>959</td>\n",
       "      <td>can</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>996</td>\n",
       "      <td>cna</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>713</td>\n",
       "      <td>can</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>784</td>\n",
       "      <td>can</td>\n",
       "      <td>train_ppl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy fold  iteration layout       name  repetition  sample_index  \\\n",
       "1554       NaN    0        454    can  train_ppl           0             0   \n",
       "2059       NaN    0        959    can  train_ppl           0             0   \n",
       "996        NaN    0        996    cna  train_ppl           0             0   \n",
       "1813       NaN    0        713    can  train_ppl           0             0   \n",
       "1884       NaN    0        784    can  train_ppl           0             0   \n",
       "\n",
       "      train_loss  \n",
       "1554    0.107707  \n",
       "2059    0.048804  \n",
       "996     0.024080  \n",
       "1813    0.081865  \n",
       "1884    0.039429  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = research.load_results(fold=0)\n",
    "results.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7d8f26ee8e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[1;32m   7630\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   7631\u001b[0m                        \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7632\u001b[0;31m                        observed=observed, **kwargs)\n\u001b[0m\u001b[1;32m   7633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7634\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                                                     \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'config'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "test_results = research.load_results(names= 'test_ppl_metrics', concat_config=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for i, (config, df) in enumerate(test_results.groupby('config')):\n",
    "    x, y = i//2, i%2\n",
    "    df.pivot(index='iteration', columns='fold', values='accuracy').plot(ax=ax[y])\n",
    "    ax[y].set_title(config)\n",
    "    ax[y].set_xlabel('iteration')\n",
    "    ax[y].set_ylabel('accuracy')\n",
    "    ax[y].grid(True)\n",
    "    ax[y].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation with Extra Performance Settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still use branch-root division to preprocess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research cv_branches_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 3000/3000.0 [01:13<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Empty DataFrame"
     ]
    }
   ],
   "source": [
    "model_config={\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': 10,\n",
    "    'inputs/labels/name': 'targets',\n",
    "    'initial_block/inputs': 'images',\n",
    "    'body/block/layout': C('layout'),\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "            .init_variable('train_loss')\n",
    "            .init_model('dynamic', VGG7, 'conv', config=model_config)\n",
    "            .to_array()\n",
    "            .train_model('conv', \n",
    "                         images=B('images'), labels=B('labels'),\n",
    "                         fetches='loss', save_to=V('train_loss', mode='w'))\n",
    "            .run_later(BATCH_SIZE, shuffle=True, n_epochs=None)) << mnist_train.CV(C('fold')).test\n",
    "\n",
    "augmentation_pipeline = Pipeline().salt(p=0.5).run_later(BATCH_SIZE, shuffle=True, n_epochs=None)\n",
    "\n",
    "research = (Research()\n",
    "            .add_pipeline(root=augmentation_pipeline, branch=train_template,\n",
    "                          variables='train_loss', name='train_ppl')\n",
    "            .add_pipeline(test_template, name='test_ppl',\n",
    "                          execute=TEST_EXECUTE_FREQ, run=True, import_from='train_ppl')\n",
    "            .get_metrics(pipeline='test_ppl', metrics_var='metrics', metrics_name='accuracy',\n",
    "                         returns='accuracy', \n",
    "                         execute=TEST_EXECUTE_FREQ)\n",
    "            .init_domain(domain))\n",
    "\n",
    "res_name = 'cv_branches_research'\n",
    "clear_previous_results(res_name)\n",
    "\n",
    "research.run(n_iters=ITERATIONS,\n",
    "             workers=2, devices=[0,1], \n",
    "             branches=2, \n",
    "             name=res_name, bar=True)\n",
    "\n",
    "research.load_results().info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
