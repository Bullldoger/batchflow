{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "from batchflow.opensets import Imagenette160\n",
    "from batchflow import Pipeline, B, V, C, W\n",
    "\n",
    "from batchflow.models.torch import ResNet34, ResBlock, SelfAttention\n",
    "from batchflow.models.torch.layers import ConvBlock\n",
    "\n",
    "from batchflow.models.metrics import ClassificationMetrics\n",
    "from batchflow.research import Research, Option, Results, KV, RP, REU, RI\n",
    "from batchflow.utils import plot_results_by_config, show_research, print_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "NUM_ITERS = 15000                               # number of iterations to train each model for\n",
    "N_REPS = 5                                      # number of times to repeat each model train\n",
    "RESEARCH_NAME = 'research'                      # name of Research object\n",
    "DEVICES = [4, 5, 6, 7]                          # devices to use\n",
    "WORKERS = len(DEVICES)                          # number of simultaneously trained models\n",
    "\n",
    "data = Imagenette160()                          # dataset to train models on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAResBlock(nn.Module):\n",
    "    def __init__(self, inputs=None, **kwargs):\n",
    "        super(SAResBlock, self).__init__()\n",
    "\n",
    "        self.layer = ConvBlock({'base': ResBlock, **kwargs},\n",
    "                               {'base': SelfAttention},\n",
    "                               inputs=inputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = (Option('body', [KV({'encoder/blocks/base':ResBlock, 'encoder/blocks/se': False},\n",
    "                             'ResBlock'),\n",
    "                          KV({'encoder/blocks/base':SAResBlock},\n",
    "                             'SAResBlock'), \n",
    "                          KV({'encoder/blocks/base':ResBlock, 'encoder/blocks/se': True},\n",
    "                             'SEResBlock'),\n",
    "                          KV({'encoder/blocks/base':SAResBlock, 'encoder/blocks/se': True},\n",
    "                             'SESAResBlock')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'inputs/labels/classes': 10,\n",
    "    'body': C('body'),\n",
    "    'head/layout': 'cV',\n",
    "    'device': C('device'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = (data.train.p      \n",
    "                  .crop(shape=(160, 160), origin='center')\n",
    "                  .to_array(channels='first', dtype=np.float32)\n",
    "                  .run_later(64, n_epochs=None, drop_last=True,\n",
    "                             shuffle=True)\n",
    "                   )\n",
    "\n",
    "train_pipeline = (Pipeline()\n",
    "                  .init_variable('loss')\n",
    "                  .init_model('dynamic', ResNet34, 'my_model', config=config) \n",
    "                  .train_model('my_model', B('images'), B('labels'), \n",
    "                               fetches='loss', save_to=V('loss'))\n",
    "                 )\n",
    "\n",
    "test_pipeline = (data.train.p\n",
    "                 .import_model('my_model', C('import_from'))\n",
    "                 .init_variable('true', [])\n",
    "                 .update(V('true', mode='a'), B.labels) \n",
    "                 .init_variable('predictions', [])\n",
    "                 .crop(shape=(160, 160), origin='center')\n",
    "                 .to_array(channels='first', dtype=np.float32)\n",
    "                 .predict_model('my_model', B('images'), fetches='predictions',\n",
    "                                save_to=V('predictions', mode='a'))\n",
    "                 .run_later(128, n_epochs=1, drop_last=False,\n",
    "                            shuffle=True)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(iteration, experiment):\n",
    "    pipeline = experiment.pipeline\n",
    "    pred = np.concatenate(pipeline.v('predictions'))\n",
    "    true = np.concatenate(pipeline.v('true'))\n",
    "    accuracy = ClassificationMetrics(true, pred, fmt='logits',\n",
    "                                     num_classes=10, axis=1).accuracy()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "            .init_domain(domain, n_reps=N_REPS)\n",
    "            .add_pipeline(root=train_root, branch=train_pipeline, variables='loss',\n",
    "                          name='train_ppl', logging=True)\n",
    "            .add_pipeline(test_pipeline, name='test_ppl',\n",
    "                          execute=10, run=True, import_from=RP('train_ppl'))\n",
    "            .add_callable(acc, returns='acc_vall', name='acc_fn',\n",
    "                          execute=10, iteration=RI(), experiment=REU('test_ppl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research.run(NUM_ITERS, name=RESEARCH_NAME,\n",
    "             devices=DEVICES, workers=WORKERS,\n",
    "             bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = research.load_results(concat_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggreg(values):\n",
    "    values = list(values)\n",
    "    values = [item for item in values if not pd.isna(item)]\n",
    "    return np.mean(values[-3:])\n",
    "\n",
    "(results.df\n",
    " .groupby(['config'])['sample_index', 'acc_vall']\n",
    " .agg(aggreg)\n",
    " .reset_index()\n",
    " .sort_values('acc_vall', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_research(results.df, layout=['train_ppl/loss', 'acc_fn/acc_vall'], average_repetitions=True, \n",
    "              color=list(mcolors.TABLEAU_COLORS.keys()), log_scale=False, rolling_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(results.df, 'acc_fn/acc_vall', False, ascending=True, n_last=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_results_by_config(results.df, (('train_ppl', 'loss'), ('acc_fn', 'acc_vall')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
