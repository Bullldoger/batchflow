{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:12.900Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "from batchflow import *\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.eager_torch import EagerTorch\n",
    "from batchflow.models.eager_torch.layers import ConvBlock\n",
    "\n",
    "# Set GPU\n",
    "# %env CUDA_VISIBLE_DEVICES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:12.929Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = 2*np.ones((6, 3, 28, 28), dtype=np.float32)\n",
    "inputs = torch.from_numpy(inputs)\n",
    "tuple(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:12.956Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ConvBlock(inputs=inputs, layout='Rca.ccav', filters=[6, 12, 18], activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:12.987Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.037Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = MNIST(batch_class=ImagesBatch)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MICROBATCH = None\n",
    "    DEVICE = None\n",
    "\n",
    "print('\\nMicrobatching is: {}'.format(MICROBATCH))\n",
    "print('\\nDevice is: {}'.format(DEVICE))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.070Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (1, 28, 28)\n",
    "\n",
    "def get_classification_config(model_class, config):\n",
    "    default_config = {\n",
    "#         'inputs/images/shape': IMAGE_SHAPE,\n",
    "#         'inputs/labels/classes': 10,\n",
    "#         'initial_block/inputs': 'images',\n",
    "        'loss': 'ce',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "\n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'feed_dict': {'images': B('images'),\n",
    "                      'labels': B('labels')},\n",
    "    }\n",
    "    return pipeline_config\n",
    "\n",
    "def get_segmentation_config(model_class, config):\n",
    "    default_config = {\n",
    "#         'inputs/images/shape': IMAGE_SHAPE,\n",
    "#         'inputs/masks/shape': IMAGE_SHAPE,\n",
    "#         'initial_block/inputs': 'images',\n",
    "        'body/decoder/blocks/combine_op': 'concat', # for some reason `concat` is not working from within pytest \n",
    "        'loss': 'mse',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "    \n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'feed_dict': {'images': B('images'),\n",
    "                      'masks': B('images')},\n",
    "    }\n",
    "    return pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.103Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline(pipeline_config):\n",
    "    \"\"\" Pipeline config must contain 'model', 'model_config', 'feed_dict' keys. \"\"\"\n",
    "    vals = pipeline_config['feed_dict'].values()\n",
    "\n",
    "    pipeline = (Pipeline(config=pipeline_config)\n",
    "                .init_variable('loss_history', [])\n",
    "#                 .multiply(multiplier=1/255., preserve_type=False)\n",
    "                .to_array(channels='first', dtype='float32')\n",
    "                .init_model('dynamic', C('model'),\n",
    "                            'MODEL', config=C('model_config'))\n",
    "                .train_model('MODEL', *vals,\n",
    "                             fetches='loss',\n",
    "                             save_to=V('loss_history', mode='a'))\n",
    "                )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.132Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(task, model_class, config, description, batch_size=16, n_iters=10):\n",
    "    if task.startswith('c'):\n",
    "        pipeline_config = get_classification_config(model_class, config)\n",
    "    elif task.startswith('s'):\n",
    "        pipeline_config = get_segmentation_config(model_class, config)\n",
    "        \n",
    "    train_pipeline = get_pipeline(pipeline_config) << mnist.train\n",
    "    _ = train_pipeline.run(batch_size, n_iters=n_iters, bar=True,\n",
    "                           bar_desc=W(V('loss_history')[-1].format('Loss is {:7.7}')))\n",
    "    \n",
    "    print('{} {} is done'.format(task, description))\n",
    "    return train_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.159Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "#     'inputs/images/shape': IMAGE_SHAPE,\n",
    "#     'inputs/labels/classes': 10,\n",
    "#     'initial_block/inputs': 'images',\n",
    "    'loss': ['ce', 'ce'],\n",
    "    'decay': 'exp',\n",
    "    'n_iters': 25,\n",
    "    'train_steps': {'a': {}, 'b': {}},\n",
    "    'initial_block': {'layout': 'fafaf', 'units': [128, 256, 10]},\n",
    "    'order': ['initial_block', ('ib_2', 'initial_block', EagerTorch.initial_block)],\n",
    "}\n",
    "\n",
    "\n",
    "ppl = run('classification', EagerTorch, config, 'simple fc', n_iters=99, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.186Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(ppl.v('loss_history'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.213Z"
    }
   },
   "outputs": [],
   "source": [
    "ppl.get_model_by_name('MODEL').devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.242Z"
    }
   },
   "outputs": [],
   "source": [
    "ppl.get_model_by_name('MODEL').full_config['train_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.266Z"
    }
   },
   "outputs": [],
   "source": [
    "ppl.get_model_by_name('MODEL').train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.290Z"
    }
   },
   "outputs": [],
   "source": [
    "from batchflow.models.eager_torch.layers import Combine\n",
    "\n",
    "class TestModel(EagerTorch):\n",
    "    @classmethod\n",
    "    def body(cls, inputs, **kwargs):\n",
    "        \"\"\" Truly amazing docstring. \"\"\"\n",
    "        kwargs = cls.get_defaults('body', kwargs)\n",
    "        return BodyModule(inputs=inputs, **kwargs)\n",
    "    \n",
    "class BodyModule(nn.Module):\n",
    "    def __init__(self, inputs=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.x1 = ConvBlock(inputs=inputs, **kwargs)\n",
    "        self.x2 = ConvBlock(inputs=inputs, **kwargs)\n",
    "        \n",
    "        self.combine = Combine(op='concat')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.x1(x)\n",
    "        x2 = self.x2(x)\n",
    "        return self.combine([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.309Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'Rcna. p cnap',\n",
    "                      'filters': [16, 32], 'scale_factor': 2,},\n",
    "    'body': {'layout': 'ca'*2,\n",
    "             'filters': [32, 32]},\n",
    "#     'body': {'module': BodyModule, 'module_kwargs': {'layout': 'cnacna',\n",
    "#                                                      'filters': [32, 32]}\n",
    "#              },\n",
    "    'head': {'layout': 'Dnfaf',\n",
    "             'units': [600,10], 'dropout_rate': 0.3},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TestModel, config, 'simple fc', n_iters=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.336Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pipeline = (mnist.test.p\n",
    "                .import_model('MODEL', ppl)\n",
    "                .init_variable('predictions')\n",
    "                .init_variable('metrics', init_on_each_run=None) \n",
    "                .to_array(channels='first', dtype='float32')\n",
    "#                 .train_model('MODEL', B.images, B.labels,\n",
    "#                                fetches='predictions', save_to=V('predictions'))\n",
    "                .predict_model('MODEL', B.images,\n",
    "                               fetches='predictions', save_to=V('predictions'))\n",
    "                .gather_metrics('class', targets=B.labels, predictions=V('predictions'),\n",
    "                                fmt='logits', axis=-1, save_to=V('metrics', mode='w'))\n",
    "                .run(64, shuffle=True, n_epochs=1, drop_last=False, bar=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.361Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(ppl.v('loss_history'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.396Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = test_pipeline.get_variable('metrics')\n",
    "metrics.evaluate('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.418Z"
    }
   },
   "outputs": [],
   "source": [
    "ppl.get_model_by_name('MODEL').model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.438Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     'initial_block/filters': 4,\n",
    "#     'body/encoder': {'num_stages': 3},\n",
    "# }\n",
    "\n",
    "config = {\n",
    "    'sync_every': 1,\n",
    "    'initial_block': {\n",
    "#         'layout': 'cnap AAbcna++ c',\n",
    "        'layout': 'cnaRp cnaRp tna+ tna+ cnac',\n",
    "        'filters': [16, 32, 32, 16, 8, 1],\n",
    "        'kernel_size': [3, 3, 2, 2, 3, 3],\n",
    "        'strides':     [1, 1, 2, 2, 1, 1],\n",
    "        'scale_factor': 2, 'mode': 'bicubic'},\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', EagerTorch, config, 'unet?', n_iters=1000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-05T15:03:13.459Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(ppl.v('loss_history'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
