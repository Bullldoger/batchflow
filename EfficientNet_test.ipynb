{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 15:46:28.086140 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/losses/dice.py:6: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0911 15:46:28.087600 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/losses/dice.py:6: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0911 15:46:28.089424 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:22: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "W0911 15:46:28.090591 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:23: The name tf.losses.sigmoid_cross_entropy is deprecated. Please use tf.compat.v1.losses.sigmoid_cross_entropy instead.\n",
      "\n",
      "W0911 15:46:28.091332 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:26: The name tf.losses.absolute_difference is deprecated. Please use tf.compat.v1.losses.absolute_difference instead.\n",
      "\n",
      "W0911 15:46:28.092017 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:30: The name tf.losses.hinge_loss is deprecated. Please use tf.compat.v1.losses.hinge_loss instead.\n",
      "\n",
      "W0911 15:46:28.092685 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:37: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "W0911 15:46:28.093734 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:38: The name tf.train.inverse_time_decay is deprecated. Please use tf.compat.v1.train.inverse_time_decay instead.\n",
      "\n",
      "W0911 15:46:28.097547 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:39: The name tf.train.natural_exp_decay is deprecated. Please use tf.compat.v1.train.natural_exp_decay instead.\n",
      "\n",
      "W0911 15:46:28.100205 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:41: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from time import sleep\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from batchflow.models.tf import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchflow import Pipeline, B, V, C, D, ImagesBatch\n",
    "from batchflow.opensets import CIFAR10\n",
    "from batchflow.research import Option, Research, Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "cifar = CIFAR10(batch_class=ImagesBatch, bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = EfficientNetB0.resolution\n",
    "im_shape = (new_res, new_res, 3)\n",
    "\n",
    "model_config = {\n",
    "    'inputs/images/shape': im_shape,\n",
    "    'inputs/labels/classes': D('num_classes'),\n",
    "    'initial_block/inputs': 'images',\n",
    "    'loss': 'ce'\n",
    "}\n",
    "\n",
    "train_ppl = (cifar.train.p\n",
    "                  .resize((new_res, new_res))\n",
    "                  .init_variable('loss_history', default=[])\n",
    "                  .init_model('dynamic', EfficientNetB0, 'mnist_model', config=model_config)\n",
    "                  .to_array()\n",
    "                  .train_model('mnist_model', fetches='loss', images=B('images'), labels=B('labels'), \n",
    "                               save_to=V('loss_history', mode='a'))\n",
    "                  .run_later(64, shuffle=True, n_epochs=1, drop_last=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/781 [00:00<?, ?it/s]W0911 15:46:34.600257 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:319: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0911 15:46:34.602431 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:321: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0911 15:46:34.611655 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:380: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W0911 15:46:34.620984 140350399465280 deprecation.py:323] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/layers/conv.py:26: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0911 15:46:34.623983 140350399465280 deprecation.py:506] From /home/antonina/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 15:46:34.870662 140350399465280 deprecation.py:323] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/layers/block.py:221: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0911 15:46:35.193624 140350399465280 deprecation.py:323] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/layers/block.py:221: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0911 15:46:40.385673 140350399465280 deprecation.py:323] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/layers/block.py:221: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0911 15:46:40.480778 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:347: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0911 15:46:40.482063 140350399465280 deprecation_wrapper.py:119] From /media/data/Data/source/github/analysiscenter/batchflow/batchflow/models/tf/base.py:764: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0911 15:46:40.543710 140350399465280 deprecation.py:323] From /home/antonina/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "train_ppl1 = train_ppl.run(bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(train_pipeline.get_variable('loss_history'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': D('num_classes'),\n",
    "    'initial_block/inputs': 'images',\n",
    "    \n",
    "    'common/width_factor': C('width_factor'),\n",
    "    'common/depth_factor': C('depth_factor'),\n",
    "    \n",
    "    'loss': 'crossentropy',\n",
    "    'optimizer': 'Adam', \n",
    "}\n",
    "\n",
    "train_ppl = (dataset.train.p\n",
    "                  .init_variable('loss') \n",
    "                  .init_model('dynamic', ScalableModel, 'mnist_model', config=model_config)\n",
    "                  .to_array()\n",
    "                  .train_model('mnist_model', fetches='loss',\n",
    "                               images=B('images'), labels=B('labels'), \n",
    "                               save_to=V('loss'))\n",
    "             .run_later(BATCH_SIZE, shuffle=True, n_epochs=None))\n",
    "\n",
    "test_ppl = (dataset.test.p\n",
    "                 .import_model('mnist_model', C('import_from'))\n",
    "                 .init_variable('loss')\n",
    "                 .init_variable('predictions')\n",
    "                 .init_variable('metrics')\n",
    "                 .to_array()\n",
    "                 .predict_model('mnist_model', fetches=['loss', 'predictions'],\n",
    "                                images=B('images'), labels=B('labels'), \n",
    "                                save_to=[V('loss'), V('predictions')])\n",
    "                 .gather_metrics('class', targets=B('labels'), predictions=V('predictions'),\n",
    "                                 fmt='logits', axis=-1, save_to=V('metrics'))\n",
    "            .run_later(BATCH_SIZE, shuffle=True, n_epochs=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1 = Option('width_factor', [1, 1.5, 2])\n",
    "op2 = Option('depth_factor', [1, 2])\n",
    "grid = op1 * op2\n",
    "\n",
    "list(grid.gen_configs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "            .add_pipeline(train_ppl, variables='loss', name='train')\n",
    "            .add_pipeline(test_ppl, variables='loss', name='test', execute=10,\n",
    "                          run=True, import_from='train')\n",
    "            .get_metrics(pipeline='test', metrics_var='metrics', metrics_name='accuracy',\n",
    "                         returns='accuracy', execute=10)\n",
    "            .add_grid(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r scalable_research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_REPEATS = 3\n",
    "NUM_ITERS = 100\n",
    "research_name = 'scalable_research'\n",
    "\n",
    "research.run(n_reps=NUM_REPEATS, n_iters=NUM_ITERS, name=research_name, bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = research.load_results(use_alias=True)\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchflow.utils import plot_results_by_config\n",
    "\n",
    "plot_results_by_config(res, (('train', 'loss'), ('test', 'loss'), ('test_metrics', 'accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'inputs/images/shape': B('image_shape'),\n",
    "    'inputs/labels/classes': D('num_classes'),\n",
    "    'initial_block/inputs': 'images',\n",
    "    \n",
    "    'common/width_factor': 3,\n",
    "    'common/depth_factor': 2,\n",
    "    \n",
    "    'loss': 'crossentropy',\n",
    "    'optimizer': 'Adam', #('Momentum', {'use_nesterov': True, 'learning_rate': 0.01, 'momentum': 0.5}),\n",
    "#     'output': ['proba']\n",
    "}\n",
    "\n",
    "train_template = (Pipeline()\n",
    "                  .init_variable('loss_history', default=[])\n",
    "                  .init_model('dynamic', ScalableModel, 'mnist_model', config=model_config)\n",
    "                  .to_array()\n",
    "                  .train_model('mnist_model', fetches='loss', images=B('images'), labels=B('labels'), \n",
    "                               save_to=V('loss_history', mode='a'))\n",
    "                  .run_later(64, shuffle=True, n_epochs=1, drop_last=True, bar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (train_template << dataset.train).run()\n",
    "\n",
    "plt.plot(train_pipeline.get_variable('loss_history'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
